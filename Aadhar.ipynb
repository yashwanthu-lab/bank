{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text: ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['en'])  # English only\n",
    "results = reader.readtext('D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg')\n",
    "\n",
    "# Combine extracted text\n",
    "extracted_text = \" \".join([res[1] for res in results])\n",
    "print(\"Extracted Text:\", extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\n",
      "{\n",
      "    \"Name\": null,\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Initialize OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Aadhaar image\n",
    "image_path = \"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "result = reader.readtext(image_path, detail=0)  # Extract only text lines\n",
    "\n",
    "# Combine all text into one string\n",
    "text = \" \".join(result)\n",
    "print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "# Patterns for Aadhaar info\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract info\n",
    "aadhaar_number = re.search(aadhaar_pattern, text)\n",
    "phone_number = re.search(phone_pattern, text)\n",
    "dob = re.search(dob_pattern, text)\n",
    "gender = re.search(gender_pattern, text)\n",
    "\n",
    "# Use spaCy for Name (Proper Noun)\n",
    "doc = nlp(text)\n",
    "names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "# Create structured data\n",
    "form_data = {\n",
    "    \"Name\": names[0] if names else None,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob.group() if dob else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": text  # Later refine with address extraction\n",
    "}\n",
    "\n",
    "# Output as JSON\n",
    "print(json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ATTT', 'TET', 'GOVERNMENT OF INDIA', 'AADAAAR', 'Elon', 'Musk', 'Male', '28/06/1971', '789, Space', 'Colony', '4567', '8901', '2345', 'AT 31renr; A 48TT']\n",
      "Extracted Text:\n",
      " ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\n",
      "\n",
      "Structured Data:\n",
      " {\n",
      "    \"Name\": \"GOVERNMENT OF INDIA\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import re\n",
    "import json\n",
    "\n",
    "# -------------------------\n",
    "# Initialize EasyOCR\n",
    "# -------------------------\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# -------------------------\n",
    "# Load Aadhaar image\n",
    "# -------------------------\n",
    "image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(image_path)  # detailed output: (bbox, text, prob)\n",
    "\n",
    "# -------------------------\n",
    "# Regex patterns\n",
    "# -------------------------\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\b\\d{2}/\\d{2}/\\d{4}\\b\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|M|F)\\b\"\n",
    "\n",
    "# -------------------------\n",
    "# Extract Aadhaar Number, DOB, Gender, Phone\n",
    "# -------------------------\n",
    "text_lines = [text for bbox, text, prob in results]\n",
    "full_text = \" \".join(text_lines)\n",
    "print(text_lines)\n",
    "aadhaar_number = re.search(aadhaar_pattern, full_text)\n",
    "dob_match = re.search(dob_pattern, full_text)\n",
    "gender_match = re.search(gender_pattern, full_text)\n",
    "phone_match = re.search(phone_pattern, full_text)\n",
    "\n",
    "# -------------------------\n",
    "# Find Name (text above DOB)\n",
    "# -------------------------\n",
    "dob_y = None\n",
    "for bbox, text, prob in results:\n",
    "    if re.search(dob_pattern, text):\n",
    "        dob_y = bbox[0][1]  # top-left y coordinate of DOB\n",
    "        break\n",
    "\n",
    "name_candidates = []\n",
    "if dob_y:\n",
    "    for bbox, text, prob in results:\n",
    "        if bbox[0][1] < dob_y:  # lines above DOB\n",
    "            name_candidates.append(text)\n",
    "\n",
    "# Heuristic: usually the longest line above DOB is the name\n",
    "name = max(name_candidates, key=len) if name_candidates else None\n",
    "\n",
    "# -------------------------\n",
    "# Extract Address (lines after Aadhaar Number)\n",
    "# -------------------------\n",
    "aadhaar_y = None\n",
    "for bbox, text, prob in results:\n",
    "    if re.search(aadhaar_pattern, text):\n",
    "        aadhaar_y = bbox[0][1]  # top-left y coordinate of Aadhaar Number\n",
    "        break\n",
    "\n",
    "address_lines = []\n",
    "if aadhaar_y:\n",
    "    for bbox, text, prob in results:\n",
    "        if bbox[0][1] > aadhaar_y:\n",
    "            address_lines.append(text)\n",
    "\n",
    "address = \", \".join(address_lines) if address_lines else None\n",
    "\n",
    "# -------------------------\n",
    "# Build JSON output\n",
    "# -------------------------\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender_match.group() if gender_match else None,\n",
    "    \"Phone\": phone_match.group() if phone_match else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Output result\n",
    "# -------------------------\n",
    "print(\"Extracted Text:\\n\", full_text)\n",
    "print(\"\\nStructured Data:\\n\", json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Data:\n",
      " {\n",
      "    \"Name\": null,\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Initialize EasyOCR and spaCy\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Aadhaar image\n",
    "image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(image_path)  # Get bbox, text, prob\n",
    "\n",
    "# Extract text with positions\n",
    "lines = []\n",
    "for bbox, text, prob in results:\n",
    "    # bbox[0][1] is top-left y coordinate\n",
    "    lines.append({'text': text, 'y': bbox[0][1]})\n",
    "\n",
    "# Combine all text for regex extraction\n",
    "all_text = \" \".join([line['text'] for line in lines])\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract Aadhaar, DOB, Gender, Phone\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "dob_y = None\n",
    "if dob_match:\n",
    "    # Find y-coordinate of DOB line\n",
    "    for line in lines:\n",
    "        if dob_match.group() in line['text']:\n",
    "            dob_y = line['y']\n",
    "            break\n",
    "\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Extract Name using spaCy + layout\n",
    "headers = [\"GOVERNMENT OF INDIA\", \"AADHAAR\", \"UNIQUE IDENTIFICATION AUTHORITY OF INDIA\"]\n",
    "\n",
    "name_candidates = []\n",
    "for line in lines:\n",
    "    text_upper = line['text'].upper()\n",
    "    if dob_y and line['y'] < dob_y and text_upper not in headers:\n",
    "        # Check if it contains a PERSON entity\n",
    "        doc = nlp(line['text'])\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                name_candidates.append((ent.text, line['y']))\n",
    "\n",
    "# Pick the candidate closest to DOB\n",
    "name = None\n",
    "if name_candidates:\n",
    "    # Closest to DOB from above\n",
    "    name = max(name_candidates, key=lambda x: x[1])[0]\n",
    "\n",
    "# Address: everything below name & DOB as a fallback\n",
    "address_candidates = []\n",
    "for line in lines:\n",
    "    if name and line['y'] > [y for t, y in name_candidates if t == name][0]:\n",
    "        address_candidates.append(line['text'])\n",
    "address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# Structured data\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "# Output JSON\n",
    "print(\"Structured Data:\\n\", json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Data:\n",
      " {\n",
      "    \"Name\": \"Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Initialize EasyOCR and spaCy\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Aadhaar image\n",
    "image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(image_path)  # Get bbox, text, prob\n",
    "\n",
    "# Extract text lines\n",
    "lines = [text for _, text, _ in results]\n",
    "\n",
    "# Combine all text for regex extraction\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract Aadhaar, DOB, Gender, Phone\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Find name based on DOB position\n",
    "name = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    if dob_text in lines:\n",
    "        dob_index = lines.index(dob_text)\n",
    "    else:\n",
    "        # Search line that contains DOB text\n",
    "        dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    \n",
    "    if dob_index is not None and dob_index >= 2:\n",
    "        name_candidate = lines[dob_index - 2]\n",
    "        # Optional: clean name (remove unwanted words like \"GOVERNMENT\")\n",
    "        if \"GOVERNMENT\" not in name_candidate.upper() and \"INDIA\" not in name_candidate.upper():\n",
    "            name = name_candidate\n",
    "        else:\n",
    "            name = lines[dob_index - 1]  # fallback to previous line\n",
    "\n",
    "# Address: take everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# Structured data\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "# Output JSON\n",
    "print(\"Structured Data:\\n\", json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Data:\n",
      " {\n",
      "    \"Name\": \"Musk Male\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Initialize OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Aadhaar image\n",
    "image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(image_path)  # Get bbox, text, prob\n",
    "\n",
    "# Extract text lines\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "\n",
    "# Combine all text for regex\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: two lines above DOB\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "\n",
    "    if dob_index is not None:\n",
    "        # Take two lines above DOB if available\n",
    "        candidate_lines = []\n",
    "        if dob_index - 2 :\n",
    "            candidate_lines.append(lines[dob_index - 2])\n",
    "        if dob_index - 1:\n",
    "            candidate_lines.append(lines[dob_index - 1])\n",
    "\n",
    "        # Merge and clean\n",
    "        merged_text = \" \".join(candidate_lines)\n",
    "        # Remove headers like \"GOVERNMENT OF INDIA\" or \"AADHAAR\"\n",
    "        for header in [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\"]:\n",
    "            merged_text = re.sub(header, \"\", merged_text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "        # Use spaCy to get PERSON entity from merged text\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)  # Take full name if multiple detected\n",
    "        else:\n",
    "            name = merged_text  # Fallback to merged text\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# Structured data\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "# Output JSON\n",
    "print(\"Structured Data:\\n\", json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Data:\n",
      " {\n",
      "    \"Name\": \"Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Initialize OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Aadhaar image\n",
    "image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(image_path)  # Get bbox, text, prob\n",
    "\n",
    "# Extract text lines\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "\n",
    "# Combine all text for regex\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: two lines above DOB\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "\n",
    "    if dob_index is not None:\n",
    "        # Take two lines above DOB if available\n",
    "        candidate_lines = []\n",
    "        if dob_index - 2 >= 0:\n",
    "            candidate_lines.append(lines[dob_index - 2])\n",
    "        if dob_index - 1 >= 0:\n",
    "            candidate_lines.append(lines[dob_index - 1])\n",
    "\n",
    "        # Merge candidate lines\n",
    "        merged_text = \" \".join(candidate_lines)\n",
    "\n",
    "        # Remove gender words and headers\n",
    "        merged_text = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", merged_text)\n",
    "        for header in [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\"]:\n",
    "            merged_text = re.sub(header, \"\", merged_text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "        # Use spaCy to detect PERSON names\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "        if len(person_names) > 1:\n",
    "            name = \" \".join(person_names)  # Combine first + last name\n",
    "        elif len(person_names) == 1:\n",
    "            name = person_names[0]\n",
    "        else:\n",
    "            # Fallback: take tokens before gender word\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])  # Assume first two tokens are name\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    # Remove Aadhaar number from address\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# Structured data\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "# Output JSON\n",
    "print(\"Structured Data:\\n\", json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Initialize OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Aadhaar image\n",
    "image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(image_path)  # Get bbox, text, prob\n",
    "\n",
    "# Extract text lines\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "\n",
    "# Combine all text for regex\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: take ALL lines above DOB, clean them, detect PERSON\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "\n",
    "    if dob_index is not None:\n",
    "        # Take all lines above DOB\n",
    "        candidate_lines = lines[:dob_index]\n",
    "\n",
    "        # Remove headers and gender words\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            # Remove gender\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            # Remove header keywords\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "\n",
    "        # Merge into single string\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "\n",
    "        # Use spaCy to detect PERSON names\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            # Fallback: take first two cleaned tokens\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    # Remove Aadhaar number from address\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# Structured data\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "# Output JSON\n",
    "print(\"Structured Data:\\n\", json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n",
      "✅ Form filled and saved at: D:\\Form_automation\\Output\\filled_form.jpg\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import numpy as np\n",
    "\n",
    "# Initialize OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Aadhaar image path\n",
    "aadhar_image = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "\n",
    "# Read Aadhaar image text\n",
    "results = reader.readtext(aadhar_image)\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Extract Name (all lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# Structured data\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"Extracted Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ===================== FORM FILLING PART =====================\n",
    "\n",
    "# Load form image\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path)\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "\n",
    "# Font settings\n",
    "font = ImageFont.truetype(\"arial.ttf\", 12)  # Adjust font size\n",
    "\n",
    "# Coordinates for fields (you need to find these by inspecting your form)\n",
    "coords = {\n",
    "    \"Name\": (138, 135),\n",
    "    \"Aadhaar Number\": (300, 350),\n",
    "    \"Date of Birth\": (300, 450),\n",
    "    \"Gender\": (300, 550),\n",
    "    \"Phone\": (300, 650),\n",
    "    \"Address\": (300, 750)\n",
    "}\n",
    "\n",
    "# Write text on form\n",
    "for key, value in form_data.items():\n",
    "    if value:\n",
    "        draw.text(coords[key], value, font=font, fill=(0, 0, 0))\n",
    "\n",
    "# Save filled form\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = r\"D:\\Form_automation\\Output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save filled form\n",
    "output_path = os.path.join(output_dir, \"filled_form.jpg\")\n",
    "form_img.save(output_path)\n",
    "\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting layoutparser\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser) (2.2.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser) (4.12.0.88)\n",
      "Requirement already satisfied: scipy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser) (1.15.3)\n",
      "Collecting pandas (from layoutparser)\n",
      "  Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser) (6.0.2)\n",
      "Collecting iopath (from layoutparser)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pdfplumber (from layoutparser)\n",
      "  Using cached pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdf2image (from layoutparser)\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser) (4.14.1)\n",
      "Collecting portalocker (from iopath->layoutparser)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pandas->layoutparser) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->layoutparser)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->layoutparser)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->layoutparser) (1.17.0)\n",
      "Collecting pdfminer.six==20250506 (from pdfplumber->layoutparser)\n",
      "  Using cached pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser)\n",
      "  Using cached pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber->layoutparser) (3.4.3)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->pdfplumber->layoutparser)\n",
      "  Downloading cryptography-45.0.6-cp37-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber->layoutparser)\n",
      "  Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber->layoutparser)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from portalocker->iopath->layoutparser) (311)\n",
      "Requirement already satisfied: colorama in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from tqdm->iopath->layoutparser) (0.4.6)\n",
      "Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "   ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 10.0/19.2 MB 47.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 17.0/19.2 MB 41.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.2/19.2 MB 31.9 MB/s eta 0:00:00\n",
      "Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.3 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.3 MB 21.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 22.9 MB/s eta 0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Using cached pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "Using cached pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "Downloading cryptography-45.0.6-cp37-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/3.4 MB 33.3 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Using cached pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: iopath\n",
      "  Building wheel for iopath (setup.py): started\n",
      "  Building wheel for iopath (setup.py): finished with status 'done'\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31606 sha256=70edac932329f320a732fbed1cbdc4a1fe4bbc6a07c23e5112f76249d8ce3e8f\n",
      "  Stored in directory: c:\\users\\t077\\appdata\\local\\pip\\cache\\wheels\\9a\\a3\\b6\\ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
      "Successfully built iopath\n",
      "Installing collected packages: pytz, tzdata, pypdfium2, pycparser, portalocker, pdf2image, pandas, iopath, cffi, cryptography, pdfminer.six, pdfplumber, layoutparser\n",
      "\n",
      "   ----------------------------------------  0/13 [pytz]\n",
      "   ----------------------------------------  0/13 [pytz]\n",
      "   ----------------------------------------  0/13 [pytz]\n",
      "   --- ------------------------------------  1/13 [tzdata]\n",
      "   --- ------------------------------------  1/13 [tzdata]\n",
      "   --- ------------------------------------  1/13 [tzdata]\n",
      "   --- ------------------------------------  1/13 [tzdata]\n",
      "   ------ ---------------------------------  2/13 [pypdfium2]\n",
      "   ------ ---------------------------------  2/13 [pypdfium2]\n",
      "   --------- ------------------------------  3/13 [pycparser]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------ ---------------------  6/13 [pandas]\n",
      "   ------------------------ ---------------  8/13 [cffi]\n",
      "   --------------------------- ------------  9/13 [cryptography]\n",
      "   --------------------------- ------------  9/13 [cryptography]\n",
      "   ------------------------------ --------- 10/13 [pdfminer.six]\n",
      "   ------------------------------ --------- 10/13 [pdfminer.six]\n",
      "   ------------------------------ --------- 10/13 [pdfminer.six]\n",
      "   --------------------------------- ------ 11/13 [pdfplumber]\n",
      "   ------------------------------------ --- 12/13 [layoutparser]\n",
      "   ---------------------------------------- 13/13 [layoutparser]\n",
      "\n",
      "Successfully installed cffi-1.17.1 cryptography-45.0.6 iopath-0.1.10 layoutparser-0.3.4 pandas-2.3.2 pdf2image-1.17.0 pdfminer.six-20250506 pdfplumber-0.11.7 portalocker-3.2.0 pycparser-2.22 pypdfium2-4.30.0 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'iopath' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'iopath'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install layoutparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'layoutparser.models.detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlayoutparser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlayoutparser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Detectron2LayoutModel\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Step 1: Extract data from Aadhaar\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize OCR and NLP\u001b[39;00m\n\u001b[0;32m     13\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'layoutparser.models.detection'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import layoutparser as lp\n",
    "from layoutparser.models.detection import Detectron2LayoutModel\n",
    "# ------------------------------\n",
    "# Step 1: Extract data from Aadhaar\n",
    "# ------------------------------\n",
    "# Initialize OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Aadhaar image\n",
    "aadhaar_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(aadhaar_path)\n",
    "\n",
    "# Extract text lines\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "\n",
    "# Combine all text for regex\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: take ALL lines above DOB, clean them, detect PERSON\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: Load form and detect text fields\n",
    "# ------------------------------\n",
    "form_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "# Load PubLayNet model to detect text boxes\n",
    "model = Detectron2LayoutModel(\n",
    "    'lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
    "    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "    label_map={0: \"Text\"}\n",
    ")\n",
    "\n",
    "layout = model.detect(image_np)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: Map extracted data to form fields\n",
    "# ------------------------------\n",
    "# You can manually map fields to boxes if form is fixed\n",
    "# Sort boxes top-to-bottom\n",
    "text_blocks = sorted([b for b in layout if b.type=='Text'], key=lambda x: x.block.y_1)\n",
    "\n",
    "# Prepare draw\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "# Fill each field\n",
    "for block in text_blocks:\n",
    "    # Example: map based on position\n",
    "    y_center = (block.block.y_1 + block.block.y_2) / 2\n",
    "    if y_center < form_img.height * 0.2:\n",
    "        # Top area -> Name\n",
    "        draw.text((block.block.x_1, block.block.y_1), name or \"\", fill=\"black\", font=font)\n",
    "    elif y_center < form_img.height * 0.35:\n",
    "        # Aadhaar Number area\n",
    "        draw.text((block.block.x_1, block.block.y_1), aadhaar_number.group() if aadhaar_number else \"\", fill=\"black\", font=font)\n",
    "    elif y_center < form_img.height * 0.5:\n",
    "        # DOB\n",
    "        draw.text((block.block.x_1, block.block.y_1), dob_match.group() if dob_match else \"\", fill=\"black\", font=font)\n",
    "    elif y_center < form_img.height * 0.65:\n",
    "        # Gender\n",
    "        draw.text((block.block.x_1, block.block.y_1), gender.group() if gender else \"\", fill=\"black\", font=font)\n",
    "    else:\n",
    "        # Address\n",
    "        draw.text((block.block.x_1, block.block.y_1), address or \"\", fill=\"black\", font=font)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 4: Save filled form\n",
    "# ------------------------------\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Step 5: Optional - print JSON\n",
    "# ------------------------------\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "print(json.dumps(form_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.1/index.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\n",
      "ERROR: No matching distribution found for detectron2\n"
     ]
    }
   ],
   "source": [
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.1/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'layoutparser.models.detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw, ImageFont\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlayoutparser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlayoutparser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Detectron2LayoutModel\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Step 1: Extract data from Aadhaar\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     14\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'layoutparser.models.detection'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "from layoutparser.models.detection import Detectron2LayoutModel\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Extract data from Aadhaar\n",
    "# -----------------------------\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Aadhaar image path\n",
    "aadhaar_img_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(aadhaar_img_path)\n",
    "\n",
    "# Extract text lines\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Extract Name (lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: lines after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "# Structured data\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Fill data into form using Layout Parser\n",
    "# -----------------------------\n",
    "# Form image path\n",
    "form_img_path = r\"D:\\Form_automation\\Form_pic\\form.jpg\"\n",
    "form_img = Image.open(form_img_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "# Load Detectron2 model for text detection\n",
    "model = Detectron2LayoutModel(\n",
    "    'lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
    "    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "    label_map={0: \"Text\"}\n",
    ")\n",
    "\n",
    "layout = model.detect(image_np)\n",
    "\n",
    "# Sort boxes top-to-bottom\n",
    "layout = sorted(layout, key=lambda b: b.coordinates[1])\n",
    "\n",
    "# Prepare to draw text\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", size=24)  # adjust size\n",
    "\n",
    "# Map fields manually (for fixed form)\n",
    "fields = [\"Name\", \"Date of Birth\", \"Aadhaar Number\", \"Gender\", \"Phone\", \"Address\"]\n",
    "field_values = [form_data.get(f) for f in fields]\n",
    "\n",
    "for box, value in zip(layout, field_values):\n",
    "    if value:\n",
    "        x1, y1, x2, y2 = map(int, box.coordinates)\n",
    "        draw.text((x1+5, y1+5), str(value), fill=\"black\", font=font)\n",
    "\n",
    "# Save filled form\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Aadhaar Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nDetectron2LayoutModel requires the detectron2 library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md and follow the ones\nthat match your environment. Typically the following would work for MacOS or Linux CPU machines:\n    pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2' \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m image_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(form_img)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Load PubLayNet model\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDetectron2LayoutModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlp://PubLayNet/faster_rcnn_R_50_FPN_3x/config\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMODEL.ROI_HEADS.SCORE_THRESH_TEST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m layout \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdetect(image_np)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Sort detected boxes top-to-bottom\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\layoutparser\\models\\base_layoutmodel.py:87\u001b[0m, in \u001b[0;36mBaseLayoutModel.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 87\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEPENDENCIES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\layoutparser\\file_utils.py:175\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    173\u001b[0m name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(BACKENDS_MAPPING[backend][\u001b[38;5;241m0\u001b[39m]() \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([BACKENDS_MAPPING[backend][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends])\n\u001b[0;32m    177\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: \nDetectron2LayoutModel requires the detectron2 library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md and follow the ones\nthat match your environment. Typically the following would work for MacOS or Linux CPU machines:\n    pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2' \n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "from layoutparser.models import Detectron2LayoutModel\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: all lines above DOB\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "# Load PubLayNet model\n",
    "model = Detectron2LayoutModel(\n",
    "    'lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
    "    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "    label_map={0: \"Text\"}\n",
    ")\n",
    "\n",
    "layout = model.detect(image_np)\n",
    "\n",
    "# Sort detected boxes top-to-bottom\n",
    "text_blocks = [b for b in layout if b.type==\"Text\"]\n",
    "text_blocks = sorted(text_blocks, key=lambda x: x.block.y_1)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Fill Form\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "\n",
    "# Manual mapping: map fields in order detected\n",
    "# Adjust these indices based on your form\n",
    "field_order = [\"Name\", \"Aadhaar Number\", \"Date of Birth\", \"Gender\", \"Phone\", \"Address\"]\n",
    "\n",
    "for i, field in enumerate(field_order):\n",
    "    if i >= len(text_blocks):\n",
    "        break\n",
    "    box = text_blocks[i].block\n",
    "    x, y = int(box.x_1), int(box.y_1)\n",
    "    draw.text((x, y), str(form_data[field]), fill=\"black\", font=font)\n",
    "\n",
    "# Save filled form\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (0.23.0)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp310-cp310-win_amd64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 72.1 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.8.0+cpu\n",
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.15/index.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\n",
      "ERROR: No matching distribution found for detectron2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: layoutparser[detectron2] in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (2.2.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (4.12.0.88)\n",
      "Requirement already satisfied: scipy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (1.15.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (2.3.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (6.0.2)\n",
      "Requirement already satisfied: iopath in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (0.11.7)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[detectron2]) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser[detectron2]) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser[detectron2]) (4.14.1)\n",
      "Requirement already satisfied: portalocker in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser[detectron2]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pandas->layoutparser[detectron2]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pandas->layoutparser[detectron2]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pandas->layoutparser[detectron2]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->layoutparser[detectron2]) (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfplumber->layoutparser[detectron2]) (20250506)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfplumber->layoutparser[detectron2]) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber->layoutparser[detectron2]) (3.4.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber->layoutparser[detectron2]) (45.0.6)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber->layoutparser[detectron2]) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber->layoutparser[detectron2]) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from portalocker->iopath->layoutparser[detectron2]) (311)\n",
      "Requirement already satisfied: colorama in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from tqdm->iopath->layoutparser[detectron2]) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: layoutparser 0.3.4 does not provide the extra 'detectron2'\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.15/index.html\n",
    "!pip install \"layoutparser[detectron2]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Aadhaar Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTesseractAgent requires the PyTesseract library but it was not found in your environment. You can install it with pip:\n`pip install pytesseract`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlayoutparser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TesseractAgent\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Tesseract-based text detection\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTesseractAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m layout \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdetect(image_np)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Sort detected boxes top-to-bottom\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\layoutparser\\ocr\\base.py:36\u001b[0m, in \u001b[0;36mBaseOCRAgent.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEPENDENCIES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\layoutparser\\file_utils.py:175\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    173\u001b[0m name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(BACKENDS_MAPPING[backend][\u001b[38;5;241m0\u001b[39m]() \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([BACKENDS_MAPPING[backend][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends])\n\u001b[0;32m    177\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: \nTesseractAgent requires the PyTesseract library but it was not found in your environment. You can install it with pip:\n`pip install pytesseract`\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: all lines above DOB\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields (Tesseract)\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "from layoutparser.ocr import TesseractAgent\n",
    "# Tesseract-based text detection\n",
    "model = TesseractAgent(languages='eng')\n",
    "layout = model.detect(image_np)\n",
    "\n",
    "# Sort detected boxes top-to-bottom\n",
    "text_blocks = sorted([b for b in layout if b.type==\"Text\"], key=lambda x: x.block.y_1)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Fill Form\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "\n",
    "field_order = [\"Name\", \"Aadhaar Number\", \"Date of Birth\", \"Gender\", \"Phone\", \"Address\"]\n",
    "\n",
    "for i, field in enumerate(field_order):\n",
    "    if i >= len(text_blocks):\n",
    "        break\n",
    "    box = text_blocks[i].block\n",
    "    x, y = int(box.x_1), int(box.y_1)\n",
    "    draw.text((x, y), str(form_data[field]), fill=\"black\", font=font)\n",
    "\n",
    "# Save filled form\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "from layoutparser.ocr import TesseractAgent\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: all lines above DOB\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "form_data = {\n",
    "    \"name\": name,\n",
    "    \"aadhaar number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"date of birth\": dob_match.group() if dob_match else None,\n",
    "    \"gender\": gender.group() if gender else None,\n",
    "    \"phone\": phone_number.group() if phone_number else None,\n",
    "    \"address\": address\n",
    "}\n",
    "\n",
    "print(\"Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields (Tesseract)\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "# Tesseract-based text detection\n",
    "model = TesseractAgent(languages='eng')\n",
    "layout = model.detect(image_np)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Map Form Fields Dynamically\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "\n",
    "for block in layout:\n",
    "    text = block.text.lower().strip()\n",
    "    x1, y1, x2, y2 = block.block.x_1, block.block.y_1, block.block.x_2, block.block.y_2\n",
    "\n",
    "    for field, value in form_data.items():\n",
    "        if field in text and value:\n",
    "            # Write after the label (x2 + offset)\n",
    "            draw.text((x2 + 20, y1), str(value), fill=\"black\", font=font)\n",
    "\n",
    "# Save filled form\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Aadhaar Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTesseractAgent requires the PyTesseract library but it was not found in your environment. You can install it with pip:\n`pip install pytesseract`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# LayoutParser TesseractAgent for structured OCR\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlayoutparser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TesseractAgent\n\u001b[1;32m---> 93\u001b[0m ocr_agent \u001b[38;5;241m=\u001b[39m \u001b[43mTesseractAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m layout \u001b[38;5;241m=\u001b[39m ocr_agent\u001b[38;5;241m.\u001b[39mdetect(image_np)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Sort detected boxes (top-to-bottom)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\layoutparser\\ocr\\base.py:36\u001b[0m, in \u001b[0;36mBaseOCRAgent.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEPENDENCIES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\layoutparser\\file_utils.py:175\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    173\u001b[0m name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(BACKENDS_MAPPING[backend][\u001b[38;5;241m0\u001b[39m]() \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([BACKENDS_MAPPING[backend][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends])\n\u001b[0;32m    177\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: \nTesseractAgent requires the PyTesseract library but it was not found in your environment. You can install it with pip:\n`pip install pytesseract`\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "import pytesseract\n",
    "import pytesseract\n",
    "\n",
    "# Path to Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\T077\\AppData\\Local\\Programs\\Tesseract-OCR\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract fields\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction: all lines above DOB\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields using LayoutParser + Tesseract\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "# LayoutParser TesseractAgent for structured OCR\n",
    "from layoutparser.ocr import TesseractAgent\n",
    "ocr_agent = TesseractAgent(languages='eng')\n",
    "layout = ocr_agent.detect(image_np)\n",
    "\n",
    "# Sort detected boxes (top-to-bottom)\n",
    "text_blocks = sorted([b for b in layout if b.type == \"Text\"], key=lambda x: x.block.y_1)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Fill Form Dynamically\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "\n",
    "field_order = [\"Name\", \"Aadhaar Number\", \"Date of Birth\", \"Gender\", \"Phone\", \"Address\"]\n",
    "\n",
    "for i, field in enumerate(field_order):\n",
    "    if i >= len(text_blocks):\n",
    "        break\n",
    "    box = text_blocks[i].block\n",
    "    x, y = int(box.x_1), int(box.y_1)\n",
    "    value = form_data[field] if form_data[field] else \"\"\n",
    "    draw.text((x + 150, y), value, fill=\"black\", font=font)  # Offset to write next to label\n",
    "\n",
    "# Save filled form\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted Aadhaar Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Phone\": null,\n",
      "    \"Address\": \"789, Space, Colony, 4567, 8901, 2345, AT 31renr; A 48TT\"\n",
      "}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m layout \u001b[38;5;241m=\u001b[39m ocr_agent\u001b[38;5;241m.\u001b[39mdetect(image_np)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Sort detected text boxes top-to-bottom\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m text_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([b \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m layout \u001b[38;5;28;01mif\u001b[39;00m b\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39my_1)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Step 3: Fill Form Dynamically\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    103\u001b[0m draw \u001b[38;5;241m=\u001b[39m ImageDraw\u001b[38;5;241m.\u001b[39mDraw(form_img)\n",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     95\u001b[0m layout \u001b[38;5;241m=\u001b[39m ocr_agent\u001b[38;5;241m.\u001b[39mdetect(image_np)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Sort detected text boxes top-to-bottom\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m text_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([b \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m layout \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39my_1)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Step 3: Fill Form Dynamically\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    103\u001b[0m draw \u001b[38;5;241m=\u001b[39m ImageDraw\u001b[38;5;241m.\u001b[39mDraw(form_img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "import pytesseract\n",
    "\n",
    "# ----------------------------\n",
    "# Step 0: Setup Tesseract\n",
    "# ----------------------------\n",
    "# Update this path to your Tesseract installation\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\T077\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "\n",
    "# OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "phone_pattern = r\"\\b[6-9]\\d{9}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract data\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction (all lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1:]\n",
    "    address_candidates = [t for t in address_candidates if not re.match(aadhaar_pattern, t)]\n",
    "    address = \", \".join(address_candidates) if address_candidates else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Phone\": phone_number.group() if phone_number else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"✅ Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields using LayoutParser + Tesseract\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "# LayoutParser OCR agent\n",
    "from layoutparser.ocr import TesseractAgent\n",
    "ocr_agent = TesseractAgent(languages='eng')\n",
    "layout = ocr_agent.detect(image_np)\n",
    "\n",
    "# Sort detected text boxes top-to-bottom\n",
    "text_blocks = sorted([b for b in layout if b.type == \"Text\"], key=lambda x: x.block.y_1)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Fill Form Dynamically\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 24)  # Adjust font size\n",
    "\n",
    "# Map data fields to form labels (order based on form design)\n",
    "field_order = [\"Name\", \"Aadhaar Number\", \"Date of Birth\", \"Gender\", \"Phone\", \"Address\"]\n",
    "\n",
    "for i, field in enumerate(field_order):\n",
    "    if i >= len(text_blocks):\n",
    "        break\n",
    "    box = text_blocks[i].block\n",
    "    x, y = int(box.x_1), int(box.y_1)\n",
    "    value = form_data[field] if form_data[field] else \"\"\n",
    "    draw.text((x + 150, y), value, fill=\"black\", font=font)  # Offset to align next to label\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Save Filled Form\n",
    "# ----------------------------\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\n",
      "✅ Extracted Aadhaar Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Address\": \"789, Space Colony\"\n",
      "}\n",
      "✅ Form filled and saved at: D:\\Form_automation\\Output\\filled_form.jpg\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "import pytesseract\n",
    "from layoutparser.ocr import TesseractAgent\n",
    "\n",
    "# ----------------------------\n",
    "# Step 0: Setup Tesseract Path\n",
    "# ----------------------------\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\T077\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "print(all_text)\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract data\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "phone_number = re.search(phone_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction (all lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: everything after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    # Take only the next 2 lines after DOB\n",
    "    address_candidates = lines[dob_index + 1 : dob_index + 3]\n",
    "    cleaned_address_lines = []\n",
    "    for line in address_candidates:\n",
    "        # Remove only Aadhaar number (12-digit format)\n",
    "        line = re.sub(r'\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b', '', line)\n",
    "        if line.strip():\n",
    "            cleaned_address_lines.append(line.strip())\n",
    "    # Join lines to form final address\n",
    "    address = \" \".join(cleaned_address_lines) if cleaned_address_lines else None\n",
    "\n",
    "# Update form_data\n",
    "form_data[\"Address\"] = address\n",
    "\n",
    "\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"✅ Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields using LayoutParser + Tesseract\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "ocr_agent = TesseractAgent(languages='eng')\n",
    "\n",
    "# Detect layout\n",
    "layout = ocr_agent.detect(image_np, return_response=False)\n",
    "text_blocks = [b for b in layout if hasattr(b, \"type\") and b.type == \"Text\"]\n",
    "text_blocks = sorted(text_blocks, key=lambda x: x.block.y_1)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Match Labels to Data\n",
    "# ----------------------------\n",
    "# Lowercase mapping for robust matching\n",
    "label_map = {\n",
    "    \"name\": \"Name\",\n",
    "    \"aadhaar\": \"Aadhaar Number\",\n",
    "    \"aadhar\": \"Aadhaar Number\",\n",
    "    \"date of birth\": \"Date of Birth\",\n",
    "    \"dob\": \"Date of Birth\",\n",
    "    \"gender\": \"Gender\",\n",
    "    \"address\": \"Address\"\n",
    "}\n",
    "\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "\n",
    "for block in text_blocks:\n",
    "    text = block.text.strip().lower()\n",
    "    matched_key = None\n",
    "    for label in label_map:\n",
    "        if label in text:\n",
    "            matched_key = label_map[label]\n",
    "            break\n",
    "    if matched_key and matched_key in form_data:\n",
    "        value = form_data[matched_key] if form_data[matched_key] else \"\"\n",
    "        if value:\n",
    "            x, y = int(block.block.x_1), int(block.block.y_1)\n",
    "            draw.text((x + 200, y), value, fill=\"black\", font=font)  # Offset for writing next to label\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Save Filled Form\n",
    "# ----------------------------\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted Aadhaar Data:\n",
      " {\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Address\": \"789, Space Colony\"\n",
      "}\n",
      "✅ Form filled and saved at: D:\\Form_automation\\Output\\filled_form.jpg\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from layoutparser.ocr import TesseractAgent\n",
    "\n",
    "# ----------------------------\n",
    "# Step 0: Setup Tesseract Path\n",
    "# ----------------------------\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\T077\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract data\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction (all lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: only next 2 lines after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1 : dob_index + 3]\n",
    "    cleaned_address_lines = []\n",
    "    for line in address_candidates:\n",
    "        line = re.sub(r'\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b', '', line)\n",
    "        if line.strip():\n",
    "            cleaned_address_lines.append(line.strip())\n",
    "    address = \" \".join(cleaned_address_lines) if cleaned_address_lines else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"✅ Extracted Aadhaar Data:\\n\", json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields dynamically using LayoutParser\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "ocr_agent = TesseractAgent(languages='eng')\n",
    "layout = ocr_agent.detect(image_np, return_response=False)\n",
    "\n",
    "# Filter text blocks\n",
    "text_blocks = [b for b in layout if hasattr(b, \"type\") and b.type == \"Text\"]\n",
    "\n",
    "# Sort top-to-bottom\n",
    "text_blocks = sorted(text_blocks, key=lambda x: x.block.y_1)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Fill Form dynamically\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "\n",
    "# Lowercase mapping for labels\n",
    "label_map = {\n",
    "    \"name\": \"Name\",\n",
    "    \"aadhaar\": \"Aadhaar Number\",\n",
    "    \"aadhar\": \"Aadhaar Number\",\n",
    "    \"date of birth\": \"Date of Birth\",\n",
    "    \"dob\": \"Date of Birth\",\n",
    "    \"gender\": \"Gender\",\n",
    "    \"address\": \"Address\"\n",
    "}\n",
    "\n",
    "# Fill values near detected labels\n",
    "for block in text_blocks:\n",
    "    detected_text = block.text.strip().lower()\n",
    "    for label in label_map:\n",
    "        if label in detected_text:\n",
    "            field_name = label_map[label]\n",
    "            value = form_data.get(field_name, \"\")\n",
    "            if value:\n",
    "                # Use coordinates of the label block + offset\n",
    "                x = int(block.block.x_2) + 20  # start writing a bit to the right\n",
    "                y = int(block.block.y_1)\n",
    "                draw.text((x, y), value, fill=\"black\", font=font)\n",
    "            break  # Stop checking other labels for this block\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Save Filled Form\n",
    "# ----------------------------\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Extracted text from Aadhaar: ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\n",
      "✅ Extracted Aadhaar Data:\n",
      "{\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Address\": \"789, Space Colony\"\n",
      "}\n",
      "🔍 Detecting form fields using Tesseract...\n",
      "📋 Found 217 text blocks in form\n",
      "🔤 Detected text blocks:\n",
      "  0: 'FORM' at (294, 30) conf: 96\n",
      "  1: '1:' at (336, 18) conf: 82\n",
      "  2: 'Aadhaar' at (353, 30) conf: 92\n",
      "  3: 'Enrolment' at (407, 30) conf: 95\n",
      "  4: 'and' at (473, 18) conf: 95\n",
      "  5: 'Update' at (499, 30) conf: 96\n",
      "  6: 'For' at (97, 48) conf: 96\n",
      "  7: '(a)' at (121, 48) conf: 94\n",
      "  8: 'Resident' at (140, 48) conf: 95\n",
      "  9: 'Indian,' at (193, 48) conf: 96\n",
      "  10: 'or' at (238, 51) conf: 92\n",
      "  11: '(b)' at (254, 48) conf: 92\n",
      "  12: 'Non-Resident' at (274, 48) conf: 95\n",
      "  13: 'Indian' at (355, 48) conf: 95\n",
      "  14: 'having' at (397, 48) conf: 96\n",
      "  15: 'Proof' at (439, 48) conf: 96\n",
      "  16: 'of' at (476, 39) conf: 96\n",
      "  17: 'Address' at (489, 48) conf: 90\n",
      "  18: 'in' at (539, 48) conf: 96\n",
      "  19: 'India' at (554, 48) conf: 96\n",
      "  20: '(aged' at (588, 48) conf: 96\n",
      "  21: '18' at (623, 48) conf: 96\n",
      "  22: 'years' at (639, 51) conf: 96\n",
      "  23: 'and' at (673, 48) conf: 96\n",
      "  24: 'above)' at (698, 48) conf: 96\n",
      "  25: 'Please' at (141, 65) conf: 91\n",
      "  26: 'follow' at (178, 65) conf: 96\n",
      "  27: 'the' at (218, 65) conf: 96\n",
      "  28: 'instructions' at (238, 67) conf: 90\n",
      "  29: 'given' at (303, 68) conf: 96\n",
      "  30: 'below' at (336, 65) conf: 94\n",
      "  31: 'this' at (372, 65) conf: 84\n",
      "  32: 'form' at (392, 65) conf: 72\n",
      "  33: 'and' at (423, 65) conf: 96\n",
      "  34: 'use' at (447, 68) conf: 96\n",
      "  35: 'only' at (468, 65) conf: 93\n",
      "  36: 'upper' at (495, 68) conf: 89\n",
      "  37: 'case' at (529, 68) conf: 89\n",
      "  38: '(block' at (557, 65) conf: 90\n",
      "  39: 'or' at (594, 53) conf: 96\n",
      "  40: 'capital)' at (600, 65) conf: 56\n",
      "  41: 'letters.' at (654, 65) conf: 56\n",
      "  42: 'OR' at (297, 83) conf: 50\n",
      "  43: 'Update' at (360, 83) conf: 93\n",
      "  44: '2' at (65, 105) conf: 86\n",
      "  45: '[Resident' at (82, 104) conf: 75\n",
      "  46: 'status:' at (135, 105) conf: 93\n",
      "  47: '[_]Resident' at (199, 103) conf: 35\n",
      "  48: 'Indian' at (254, 104) conf: 82\n",
      "  49: 'OR' at (298, 104) conf: 58\n",
      "  50: 'Non-Resident' at (361, 104) conf: 96\n",
      "  51: 'Indian' at (439, 104) conf: 93\n",
      "  52: '(NRI)' at (476, 104) conf: 89\n",
      "  53: 'I(e)' at (584, 106) conf: 56\n",
      "  54: 'ofthe' at (604, 95) conf: 85\n",
      "  55: 'declaration' at (630, 105) conf: 74\n",
      "  56: 'below' at (682, 95) conf: 96\n",
      "  57: 'this' at (710, 95) conf: 77\n",
      "  58: 'form)' at (730, 95) conf: 67\n",
      "  59: '3' at (65, 123) conf: 75\n",
      "  60: '[Demographic' at (82, 123) conf: 88\n",
      "  61: 'information' at (167, 123) conf: 95\n",
      "  62: '(For' at (236, 124) conf: 52\n",
      "  63: 'update' at (259, 111) conf: 52\n",
      "  64: 'plas' at (292, 124) conf: 58\n",
      "  65: '[lon' at (321, 124) conf: 35\n",
      "  66: 'the' at (359, 125) conf: 84\n",
      "  67: 'formation' at (375, 124) conf: 38\n",
      "  68: 'tobe' at (428, 111) conf: 68\n",
      "  69: '(a)' at (82, 142) conf: 82\n",
      "  70: 'Name:' at (103, 129) conf: 93\n",
      "  71: 'Please' at (82, 144) conf: 59\n",
      "  72: 'fl' at (116, 158) conf: 80\n",
      "  73: 'as' at (132, 160) conf: 40\n",
      "  74: 'given' at (145, 160) conf: 40\n",
      "  75: 'in' at (169, 160) conf: 60\n",
      "  76: 'the' at (181, 157) conf: 67\n",
      "  77: 'presented' at (240, 144) conf: 42\n",
      "  78: 'nsipport' at (287, 144) conf: 42\n",
      "  79: 'ofthe' at (333, 144) conf: 87\n",
      "  80: 'POL' at (359, 158) conf: 79\n",
      "  81: 'while' at (382, 157) conf: 77\n",
      "  82: 'omiting' at (408, 160) conf: 46\n",
      "  83: 'any' at (446, 160) conf: 64\n",
      "  84: 'tiles,' at (464, 158) conf: 63\n",
      "  85: 'honorific' at (491, 157) conf: 60\n",
      "  86: 'and' at (537, 157) conf: 46\n",
      "  87: 'aliases)' at (556, 157) conf: 65\n",
      "  88: '(b)' at (82, 173) conf: 90\n",
      "  89: 'Gender:' at (102, 172) conf: 37\n",
      "  90: '[—]' at (152, 161) conf: 34\n",
      "  91: 'Female' at (178, 172) conf: 96\n",
      "  92: '(©)' at (263, 173) conf: 71\n",
      "  93: 'Date' at (281, 173) conf: 88\n",
      "  94: 'of' at (313, 173) conf: 96\n",
      "  95: 'Birth:' at (326, 173) conf: 94\n",
      "  96: '[TT' at (367, 161) conf: 53\n",
      "  97: '|' at (406, 161) conf: 45\n",
      "  98: '1111' at (419, 161) conf: 45\n",
      "  99: 'OR' at (571, 173) conf: 81\n",
      "  100: 'Age:' at (593, 173) conf: 77\n",
      "  101: '[TT]' at (623, 170) conf: 52\n",
      "  102: 'years' at (671, 176) conf: 95\n",
      "  103: 'Cate' at (82, 188) conf: 63\n",
      "  104: '(Verified' at (264, 189) conf: 39\n",
      "  105: 'OR' at (341, 191) conf: 91\n",
      "  106: '[—]Declared' at (374, 189) conf: 56\n",
      "  107: 'OR' at (455, 191) conf: 93\n",
      "  108: '[]' at (482, 189) conf: 50\n",
      "  109: 'Approximate' at (511, 191) conf: 96\n",
      "  110: '(only' at (585, 191) conf: 92\n",
      "  111: 'for' at (616, 179) conf: 92\n",
      "  112: 'age)' at (637, 179) conf: 94\n",
      "  113: '[third' at (83, 206) conf: 39\n",
      "  114: 'gender' at (142, 209) conf: 87\n",
      "  115: '/' at (182, 194) conf: 79\n",
      "  116: 'Transgender|(For' at (189, 209) conf: 66\n",
      "  117: 'declared' at (263, 208) conf: 59\n",
      "  118: 'ony' at (397, 207) conf: 57\n",
      "  119: 'yer' at (420, 210) conf: 52\n",
      "  120: 'of' at (440, 194) conf: 49\n",
      "  121: 'bird' at (549, 194) conf: 72\n",
      "  122: 'wil' at (575, 194) conf: 71\n",
      "  123: 'be' at (593, 194) conf: 79\n",
      "  124: 'printed' at (603, 207) conf: 58\n",
      "  125: 'on' at (639, 194) conf: 58\n",
      "  126: 'card)' at (692, 207) conf: 79\n",
      "  127: '(@' at (82, 227) conf: 90\n",
      "  128: 'Email:' at (102, 227) conf: 95\n",
      "  129: 'number:' at (549, 217) conf: 70\n",
      "  130: '7' at (65, 246) conf: 43\n",
      "  131: '[Basis' at (79, 246) conf: 75\n",
      "  132: 'of' at (115, 246) conf: 92\n",
      "  133: 'enrolment/update:' at (130, 246) conf: 81\n",
      "  134: '[—]Document' at (240, 245) conf: 61\n",
      "  135: 'verification' at (322, 246) conf: 77\n",
      "  136: 'OR' at (388, 246) conf: 91\n",
      "  137: 'by' at (509, 246) conf: 96\n",
      "  138: 'Head' at (526, 246) conf: 96\n",
      "  139: 'of' at (559, 246) conf: 96\n",
      "  140: 'Family' at (572, 246) conf: 93\n",
      "  141: '(HoF)' at (613, 246) conf: 81\n",
      "  142: '5' at (65, 265) conf: 83\n",
      "  143: '|For' at (82, 265) conf: 71\n",
      "  144: 'document-based' at (106, 265) conf: 92\n",
      "  145: 'enrolment/update,' at (203, 265) conf: 80\n",
      "  146: 'additional' at (312, 265) conf: 95\n",
      "  147: 'demographic' at (374, 265) conf: 96\n",
      "  148: 'information' at (452, 265) conf: 92\n",
      "  149: 'and' at (531, 265) conf: 96\n",
      "  150: 'documents' at (549, 265) conf: 96\n",
      "  151: 'presented:' at (614, 265) conf: 96\n",
      "  152: '|' at (79, 276) conf: 86\n",
      "  153: 'Adress' at (82, 276) conf: 46\n",
      "  154: 'information' at (123, 282) conf: 67\n",
      "  155: 'shouldbe' at (176, 281) conf: 77\n",
      "  156: 'filled' at (221, 271) conf: 65\n",
      "  157: 'only' at (247, 271) conf: 76\n",
      "  158: 'in' at (266, 284) conf: 87\n",
      "  159: 'case' at (278, 284) conf: 88\n",
      "  160: 'of' at (299, 271) conf: 92\n",
      "  161: 'enrolment' at (310, 282) conf: 57\n",
      "  162: 'or' at (357, 284) conf: 57\n",
      "  163: 'update' at (368, 281) conf: 47\n",
      "  164: 'of' at (401, 282) conf: 47\n",
      "  165: 'address)' at (411, 281) conf: 49\n",
      "  166: '(a)' at (82, 297) conf: 89\n",
      "  167: 'Address:' at (101, 297) conf: 72\n",
      "  168: 'Care' at (167, 297) conf: 50\n",
      "  169: 'of' at (196, 297) conf: 90\n",
      "  170: '(opional):' at (211, 297) conf: 45\n",
      "  171: 'T' at (66, 83) conf: 77\n",
      "  172: 'House' at (82, 315) conf: 94\n",
      "  173: 'no,' at (120, 318) conf: 78\n",
      "  174: '/' at (139, 315) conf: 91\n",
      "  175: 'Building' at (147, 315) conf: 92\n",
      "  176: '/' at (196, 303) conf: 76\n",
      "  177: 'Flat' at (204, 315) conf: 76\n",
      "  178: 'no.' at (228, 318) conf: 87\n",
      "  179: 'Street' at (387, 315) conf: 82\n",
      "  180: 'Landmark:' at (78, 321) conf: 89\n",
      "  181: 'Area/Locality/Sector:' at (387, 333) conf: 44\n",
      "  182: 'Village/Town/City:' at (82, 340) conf: 55\n",
      "  183: 'Post' at (320, 352) conf: 95\n",
      "  184: 'Office' at (346, 352) conf: 71\n",
      "  185: 'PIN' at (549, 352) conf: 96\n",
      "  186: 'code' at (573, 352) conf: 96\n",
      "  187: 'Suib-district:' at (82, 358) conf: 38\n",
      "  188: 'District:' at (320, 358) conf: 47\n",
      "  189: 'State:' at (549, 370) conf: 88\n",
      "  190: 'Type' at (102, 389) conf: 96\n",
      "  191: 'of' at (134, 389) conf: 96\n",
      "  192: 'documents' at (149, 389) conf: 88\n",
      "  193: 'presented:' at (214, 389) conf: 88\n",
      "  194: '(i)' at (315, 389) conf: 71\n",
      "  195: 'Proof' at (331, 389) conf: 96\n",
      "  196: 'of' at (364, 377) conf: 72\n",
      "  197: 'Identity' at (380, 389) conf: 72\n",
      "  198: '(POD:' at (423, 389) conf: 60\n",
      "  199: 'ee' at (103, 403) conf: 35\n",
      "  200: '(ii)' at (315, 408) conf: 81\n",
      "  201: 'Proof' at (335, 407) conf: 90\n",
      "  202: 'of' at (367, 402) conf: 96\n",
      "  203: 'Address' at (384, 407) conf: 93\n",
      "  204: '(POA):' at (429, 407) conf: 93\n",
      "  205: 'displayed' at (157, 414) conf: 47\n",
      "  206: 'onthe' at (202, 415) conf: 81\n",
      "  207: 'website' at (231, 415) conf: 51\n",
      "  208: 'of' at (266, 415) conf: 51\n",
      "  209: 'ee' at (104, 428) conf: 32\n",
      "  210: '(az)' at (315, 425) conf: 44\n",
      "  211: 'Proof' at (341, 415) conf: 96\n",
      "  212: 'of' at (372, 425) conf: 93\n",
      "  213: 'Datc' at (388, 425) conf: 77\n",
      "  214: 'of' at (415, 425) conf: 96\n",
      "  215: 'Birth' at (431, 415) conf: 40\n",
      "  216: '(PDB)' at (460, 425) conf: 87\n",
      "✅ Loaded Arial font\n",
      "\n",
      "📝 Filling form fields...\n",
      "\n",
      "🔍 Looking for field: Name (value: Elon Musk)\n",
      "  🎯 Found label 'Name:' for keyword 'name'\n",
      "  ✅ Filling 'Name' at position (147, 129)\n",
      "\n",
      "🔍 Looking for field: Aadhaar Number (value: 4567 8901 2345)\n",
      "  🎯 Found label 'Aadhaar' for keyword 'aadhaar'\n",
      "  ✅ Filling 'Aadhaar Number' at position (423, 30)\n",
      "\n",
      "🔍 Looking for field: Date of Birth (value: 28/06/1971)\n",
      "  🎯 Found label 'Birth:' for keyword 'birth'\n",
      "  ✅ Filling 'Date of Birth' at position (366, 173)\n",
      "\n",
      "🔍 Looking for field: Gender (value: Male)\n",
      "  🎯 Found label 'Gender:' for keyword 'gender'\n",
      "  ✅ Filling 'Gender' at position (225, 172)\n",
      "\n",
      "🔍 Looking for field: Address (value: 789, Space Colony)\n",
      "  🎯 Found label 'Address' for keyword 'address'\n",
      "  ✅ Filling 'Address' at position (555, 48)\n",
      "\n",
      "🎉 Successfully filled 5 out of 5 fields\n",
      "\n",
      "🐛 Adding debug rectangles...\n",
      "✅ Form filled and saved at: D:\\Form_automation\\Output\\filled_form.jpg\n",
      "\n",
      "📊 Summary:\n",
      "  • Extracted 5 fields from Aadhaar\n",
      "  • Detected 217 text blocks in form\n",
      "  • Successfully filled 5 fields\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "# ----------------------------\n",
    "# Step 0: Setup Tesseract Path\n",
    "# ----------------------------\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\T077\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data (Your existing code - working fine)\n",
    "# ----------------------------\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "print(f\"📄 Extracted text from Aadhaar: {all_text}\")\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract data\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction (all lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: only next 2 lines after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1 : dob_index + 3]\n",
    "    cleaned_address_lines = []\n",
    "    for line in address_candidates:\n",
    "        line = re.sub(r'\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b', '', line)\n",
    "        if line.strip():\n",
    "            cleaned_address_lines.append(line.strip())\n",
    "    address = \" \".join(cleaned_address_lines) if cleaned_address_lines else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"✅ Extracted Aadhaar Data:\")\n",
    "print(json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: FIXED Form Field Detection using Tesseract directly\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "\n",
    "def detect_form_fields_improved(image_path):\n",
    "    \"\"\"Improved form field detection using multiple methods\"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    \n",
    "    # Convert to RGB for PIL\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "    \n",
    "    # Method 1: Use Tesseract to get text with bounding boxes\n",
    "    print(\"🔍 Detecting form fields using Tesseract...\")\n",
    "    \n",
    "    # Get detailed OCR data\n",
    "    ocr_data = pytesseract.image_to_data(pil_img, output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    text_blocks = []\n",
    "    for i in range(len(ocr_data['text'])):\n",
    "        text = ocr_data['text'][i].strip()\n",
    "        conf = ocr_data['conf'][i]\n",
    "        \n",
    "        if text and conf > 30:  # Only consider confident detections\n",
    "            x, y, w, h = ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i]\n",
    "            text_blocks.append({\n",
    "                'text': text,\n",
    "                'confidence': conf,\n",
    "                'bbox': (x, y, x + w, y + h),\n",
    "                'x1': x, 'y1': y, 'x2': x + w, 'y2': y + h\n",
    "            })\n",
    "    \n",
    "    print(f\"📋 Found {len(text_blocks)} text blocks in form\")\n",
    "    \n",
    "    # Debug: Print all detected text\n",
    "    print(\"🔤 Detected text blocks:\")\n",
    "    for i, block in enumerate(text_blocks):\n",
    "        print(f\"  {i}: '{block['text']}' at ({block['x1']}, {block['y1']}) conf: {block['confidence']}\")\n",
    "    \n",
    "    return text_blocks, pil_img\n",
    "\n",
    "def find_field_fill_position(text_blocks, field_keywords):\n",
    "    \"\"\"Find the best position to fill a field based on label detection\"\"\"\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        text_lower = block['text'].lower().strip()\n",
    "        \n",
    "        # Check if this block contains any of our field keywords\n",
    "        for keyword in field_keywords:\n",
    "            if keyword.lower() in text_lower:\n",
    "                print(f\"  🎯 Found label '{block['text']}' for keyword '{keyword}'\")\n",
    "                \n",
    "                # Strategy 1: Look for colon and fill after it\n",
    "                if ':' in block['text']:\n",
    "                    # Fill right after the colon in the same block\n",
    "                    return block['x2'] + 10, block['y1']\n",
    "                \n",
    "                # Strategy 2: Look for underscore or line after the label\n",
    "                # Find text blocks that are on the same line (similar y coordinate)\n",
    "                same_line_blocks = []\n",
    "                for other_block in text_blocks:\n",
    "                    if abs(other_block['y1'] - block['y1']) < 15:  # Same line tolerance\n",
    "                        same_line_blocks.append(other_block)\n",
    "                \n",
    "                # Sort by x coordinate\n",
    "                same_line_blocks.sort(key=lambda x: x['x1'])\n",
    "                \n",
    "                # Find our label block in the sorted list\n",
    "                label_index = -1\n",
    "                for i, same_block in enumerate(same_line_blocks):\n",
    "                    if same_block['text'] == block['text']:\n",
    "                        label_index = i\n",
    "                        break\n",
    "                \n",
    "                # Look for space after the label\n",
    "                if label_index >= 0 and label_index < len(same_line_blocks) - 1:\n",
    "                    next_block = same_line_blocks[label_index + 1]\n",
    "                    # If there's a significant gap, fill in that gap\n",
    "                    if next_block['x1'] - block['x2'] > 50:\n",
    "                        return block['x2'] + 20, block['y1']\n",
    "                    # If next block might be an underscore or line, fill over it\n",
    "                    elif '_' in next_block['text'] or '___' in next_block['text']:\n",
    "                        return next_block['x1'] + 5, next_block['y1']\n",
    "                \n",
    "                # Strategy 3: Default - fill to the right of the label\n",
    "                return block['x2'] + 20, block['y1']\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Detect form fields\n",
    "text_blocks, form_img = detect_form_fields_improved(form_image_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: FIXED Form Filling Logic\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "\n",
    "# Try to load font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    print(\"✅ Loaded Arial font\")\n",
    "except:\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"calibri.ttf\", 20)\n",
    "        print(\"✅ Loaded Calibri font\")\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        print(\"⚠️ Using default font\")\n",
    "\n",
    "# Enhanced label mapping with multiple variations\n",
    "field_keywords = {\n",
    "    \"Name\": [\"name\", \"full name\", \"applicant name\", \"person name\", \"naam\"],\n",
    "    \"Aadhaar Number\": [\"aadhaar\", \"aadhar\", \"aadhaar number\", \"aadhar number\", \"uid\", \"unique id\"],\n",
    "    \"Date of Birth\": [\"date of birth\", \"dob\", \"birth date\", \"date birth\", \"birth\"],\n",
    "    \"Gender\": [\"gender\", \"sex\", \"male/female\", \"m/f\"],\n",
    "    \"Address\": [\"address\", \"residence\", \"location\", \"home address\", \"present address\"]\n",
    "}\n",
    "\n",
    "print(\"\\n📝 Filling form fields...\")\n",
    "\n",
    "filled_count = 0\n",
    "\n",
    "# Try to fill each field\n",
    "for field_name, field_value in form_data.items():\n",
    "    if field_value:  # Only fill if we have data\n",
    "        print(f\"\\n🔍 Looking for field: {field_name} (value: {field_value})\")\n",
    "        \n",
    "        # Get keywords for this field\n",
    "        keywords = field_keywords.get(field_name, [field_name.lower()])\n",
    "        \n",
    "        # Find position to fill\n",
    "        position = find_field_fill_position(text_blocks, keywords)\n",
    "        \n",
    "        if position:\n",
    "            x, y = position\n",
    "            print(f\"  ✅ Filling '{field_name}' at position ({x}, {y})\")\n",
    "            \n",
    "            # Draw the value\n",
    "            draw.text((x, y), str(field_value), fill=\"blue\", font=font)\n",
    "            filled_count += 1\n",
    "        else:\n",
    "            print(f\"  ❌ Could not find position for '{field_name}'\")\n",
    "\n",
    "print(f\"\\n🎉 Successfully filled {filled_count} out of {len([v for v in form_data.values() if v])} fields\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Save Filled Form with Debug Info\n",
    "# ----------------------------\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "\n",
    "# Optional: Draw debug rectangles around detected text blocks\n",
    "# debug_mode = True  # Set to False to disable debug rectangles\n",
    "\n",
    "# if debug_mode:\n",
    "#     print(\"\\n🐛 Adding debug rectangles...\")\n",
    "#     debug_draw = ImageDraw.Draw(form_img)\n",
    "    \n",
    "#     for i, block in enumerate(text_blocks):\n",
    "#         x1, y1, x2, y2 = block['bbox']\n",
    "#         # Draw red rectangle around detected text\n",
    "#         debug_draw.rectangle([x1-1, y1-1, x2+1, y2+1], outline=\"red\", width=1)\n",
    "#         # Add small text with block number\n",
    "#         debug_draw.text((x1, y1-15), str(i), fill=\"red\", font=font)\n",
    "\n",
    "# form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Additional Debugging Information\n",
    "# ----------------------------\n",
    "print(\"\\n📊 Summary:\")\n",
    "print(f\"  • Extracted {len([v for v in form_data.values() if v])} fields from Aadhaar\")\n",
    "print(f\"  • Detected {len(text_blocks)} text blocks in form\")\n",
    "print(f\"  • Successfully filled {filled_count} fields\")\n",
    "\n",
    "if filled_count == 0:\n",
    "    print(\"\\n🔧 Troubleshooting tips:\")\n",
    "    print(\"  1. Check if the form image is clear and readable\")\n",
    "    print(\"  2. Verify that field labels match the expected keywords\")\n",
    "    print(\"  3. Try adjusting the confidence threshold (currently 30)\")\n",
    "    print(\"  4. Check if debug rectangles appear around text in the output image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Extracted text from Aadhaar: ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\n",
      "✅ Extracted Aadhaar Data:\n",
      "{\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Address\": \"789, Space Colony\"\n",
      "}\n",
      "🔍 Detecting form fields using Tesseract...\n",
      "📋 Found 217 text blocks in form\n",
      "🔤 Detected text blocks:\n",
      "  0: 'FORM' at (294, 30) conf: 96\n",
      "  1: '1:' at (336, 18) conf: 82\n",
      "  2: 'Aadhaar' at (353, 30) conf: 92\n",
      "  3: 'Enrolment' at (407, 30) conf: 95\n",
      "  4: 'and' at (473, 18) conf: 95\n",
      "  5: 'Update' at (499, 30) conf: 96\n",
      "  6: 'For' at (97, 48) conf: 96\n",
      "  7: '(a)' at (121, 48) conf: 94\n",
      "  8: 'Resident' at (140, 48) conf: 95\n",
      "  9: 'Indian,' at (193, 48) conf: 96\n",
      "  10: 'or' at (238, 51) conf: 92\n",
      "  11: '(b)' at (254, 48) conf: 92\n",
      "  12: 'Non-Resident' at (274, 48) conf: 95\n",
      "  13: 'Indian' at (355, 48) conf: 95\n",
      "  14: 'having' at (397, 48) conf: 96\n",
      "  15: 'Proof' at (439, 48) conf: 96\n",
      "  16: 'of' at (476, 39) conf: 96\n",
      "  17: 'Address' at (489, 48) conf: 90\n",
      "  18: 'in' at (539, 48) conf: 96\n",
      "  19: 'India' at (554, 48) conf: 96\n",
      "  20: '(aged' at (588, 48) conf: 96\n",
      "  21: '18' at (623, 48) conf: 96\n",
      "  22: 'years' at (639, 51) conf: 96\n",
      "  23: 'and' at (673, 48) conf: 96\n",
      "  24: 'above)' at (698, 48) conf: 96\n",
      "  25: 'Please' at (141, 65) conf: 91\n",
      "  26: 'follow' at (178, 65) conf: 96\n",
      "  27: 'the' at (218, 65) conf: 96\n",
      "  28: 'instructions' at (238, 67) conf: 90\n",
      "  29: 'given' at (303, 68) conf: 96\n",
      "  30: 'below' at (336, 65) conf: 94\n",
      "  31: 'this' at (372, 65) conf: 84\n",
      "  32: 'form' at (392, 65) conf: 72\n",
      "  33: 'and' at (423, 65) conf: 96\n",
      "  34: 'use' at (447, 68) conf: 96\n",
      "  35: 'only' at (468, 65) conf: 93\n",
      "  36: 'upper' at (495, 68) conf: 89\n",
      "  37: 'case' at (529, 68) conf: 89\n",
      "  38: '(block' at (557, 65) conf: 90\n",
      "  39: 'or' at (594, 53) conf: 96\n",
      "  40: 'capital)' at (600, 65) conf: 56\n",
      "  41: 'letters.' at (654, 65) conf: 56\n",
      "  42: 'OR' at (297, 83) conf: 50\n",
      "  43: 'Update' at (360, 83) conf: 93\n",
      "  44: '2' at (65, 105) conf: 86\n",
      "  45: '[Resident' at (82, 104) conf: 75\n",
      "  46: 'status:' at (135, 105) conf: 93\n",
      "  47: '[_]Resident' at (199, 103) conf: 35\n",
      "  48: 'Indian' at (254, 104) conf: 82\n",
      "  49: 'OR' at (298, 104) conf: 58\n",
      "  50: 'Non-Resident' at (361, 104) conf: 96\n",
      "  51: 'Indian' at (439, 104) conf: 93\n",
      "  52: '(NRI)' at (476, 104) conf: 89\n",
      "  53: 'I(e)' at (584, 106) conf: 56\n",
      "  54: 'ofthe' at (604, 95) conf: 85\n",
      "  55: 'declaration' at (630, 105) conf: 74\n",
      "  56: 'below' at (682, 95) conf: 96\n",
      "  57: 'this' at (710, 95) conf: 77\n",
      "  58: 'form)' at (730, 95) conf: 67\n",
      "  59: '3' at (65, 123) conf: 75\n",
      "  60: '[Demographic' at (82, 123) conf: 88\n",
      "  61: 'information' at (167, 123) conf: 95\n",
      "  62: '(For' at (236, 124) conf: 52\n",
      "  63: 'update' at (259, 111) conf: 52\n",
      "  64: 'plas' at (292, 124) conf: 58\n",
      "  65: '[lon' at (321, 124) conf: 35\n",
      "  66: 'the' at (359, 125) conf: 84\n",
      "  67: 'formation' at (375, 124) conf: 38\n",
      "  68: 'tobe' at (428, 111) conf: 68\n",
      "  69: '(a)' at (82, 142) conf: 82\n",
      "  70: 'Name:' at (103, 129) conf: 93\n",
      "  71: 'Please' at (82, 144) conf: 59\n",
      "  72: 'fl' at (116, 158) conf: 80\n",
      "  73: 'as' at (132, 160) conf: 40\n",
      "  74: 'given' at (145, 160) conf: 40\n",
      "  75: 'in' at (169, 160) conf: 60\n",
      "  76: 'the' at (181, 157) conf: 67\n",
      "  77: 'presented' at (240, 144) conf: 42\n",
      "  78: 'nsipport' at (287, 144) conf: 42\n",
      "  79: 'ofthe' at (333, 144) conf: 87\n",
      "  80: 'POL' at (359, 158) conf: 79\n",
      "  81: 'while' at (382, 157) conf: 77\n",
      "  82: 'omiting' at (408, 160) conf: 46\n",
      "  83: 'any' at (446, 160) conf: 64\n",
      "  84: 'tiles,' at (464, 158) conf: 63\n",
      "  85: 'honorific' at (491, 157) conf: 60\n",
      "  86: 'and' at (537, 157) conf: 46\n",
      "  87: 'aliases)' at (556, 157) conf: 65\n",
      "  88: '(b)' at (82, 173) conf: 90\n",
      "  89: 'Gender:' at (102, 172) conf: 37\n",
      "  90: '[—]' at (152, 161) conf: 34\n",
      "  91: 'Female' at (178, 172) conf: 96\n",
      "  92: '(©)' at (263, 173) conf: 71\n",
      "  93: 'Date' at (281, 173) conf: 88\n",
      "  94: 'of' at (313, 173) conf: 96\n",
      "  95: 'Birth:' at (326, 173) conf: 94\n",
      "  96: '[TT' at (367, 161) conf: 53\n",
      "  97: '|' at (406, 161) conf: 45\n",
      "  98: '1111' at (419, 161) conf: 45\n",
      "  99: 'OR' at (571, 173) conf: 81\n",
      "  100: 'Age:' at (593, 173) conf: 77\n",
      "  101: '[TT]' at (623, 170) conf: 52\n",
      "  102: 'years' at (671, 176) conf: 95\n",
      "  103: 'Cate' at (82, 188) conf: 63\n",
      "  104: '(Verified' at (264, 189) conf: 39\n",
      "  105: 'OR' at (341, 191) conf: 91\n",
      "  106: '[—]Declared' at (374, 189) conf: 56\n",
      "  107: 'OR' at (455, 191) conf: 93\n",
      "  108: '[]' at (482, 189) conf: 50\n",
      "  109: 'Approximate' at (511, 191) conf: 96\n",
      "  110: '(only' at (585, 191) conf: 92\n",
      "  111: 'for' at (616, 179) conf: 92\n",
      "  112: 'age)' at (637, 179) conf: 94\n",
      "  113: '[third' at (83, 206) conf: 39\n",
      "  114: 'gender' at (142, 209) conf: 87\n",
      "  115: '/' at (182, 194) conf: 79\n",
      "  116: 'Transgender|(For' at (189, 209) conf: 66\n",
      "  117: 'declared' at (263, 208) conf: 59\n",
      "  118: 'ony' at (397, 207) conf: 57\n",
      "  119: 'yer' at (420, 210) conf: 52\n",
      "  120: 'of' at (440, 194) conf: 49\n",
      "  121: 'bird' at (549, 194) conf: 72\n",
      "  122: 'wil' at (575, 194) conf: 71\n",
      "  123: 'be' at (593, 194) conf: 79\n",
      "  124: 'printed' at (603, 207) conf: 58\n",
      "  125: 'on' at (639, 194) conf: 58\n",
      "  126: 'card)' at (692, 207) conf: 79\n",
      "  127: '(@' at (82, 227) conf: 90\n",
      "  128: 'Email:' at (102, 227) conf: 95\n",
      "  129: 'number:' at (549, 217) conf: 70\n",
      "  130: '7' at (65, 246) conf: 43\n",
      "  131: '[Basis' at (79, 246) conf: 75\n",
      "  132: 'of' at (115, 246) conf: 92\n",
      "  133: 'enrolment/update:' at (130, 246) conf: 81\n",
      "  134: '[—]Document' at (240, 245) conf: 61\n",
      "  135: 'verification' at (322, 246) conf: 77\n",
      "  136: 'OR' at (388, 246) conf: 91\n",
      "  137: 'by' at (509, 246) conf: 96\n",
      "  138: 'Head' at (526, 246) conf: 96\n",
      "  139: 'of' at (559, 246) conf: 96\n",
      "  140: 'Family' at (572, 246) conf: 93\n",
      "  141: '(HoF)' at (613, 246) conf: 81\n",
      "  142: '5' at (65, 265) conf: 83\n",
      "  143: '|For' at (82, 265) conf: 71\n",
      "  144: 'document-based' at (106, 265) conf: 92\n",
      "  145: 'enrolment/update,' at (203, 265) conf: 80\n",
      "  146: 'additional' at (312, 265) conf: 95\n",
      "  147: 'demographic' at (374, 265) conf: 96\n",
      "  148: 'information' at (452, 265) conf: 92\n",
      "  149: 'and' at (531, 265) conf: 96\n",
      "  150: 'documents' at (549, 265) conf: 96\n",
      "  151: 'presented:' at (614, 265) conf: 96\n",
      "  152: '|' at (79, 276) conf: 86\n",
      "  153: 'Adress' at (82, 276) conf: 46\n",
      "  154: 'information' at (123, 282) conf: 67\n",
      "  155: 'shouldbe' at (176, 281) conf: 77\n",
      "  156: 'filled' at (221, 271) conf: 65\n",
      "  157: 'only' at (247, 271) conf: 76\n",
      "  158: 'in' at (266, 284) conf: 87\n",
      "  159: 'case' at (278, 284) conf: 88\n",
      "  160: 'of' at (299, 271) conf: 92\n",
      "  161: 'enrolment' at (310, 282) conf: 57\n",
      "  162: 'or' at (357, 284) conf: 57\n",
      "  163: 'update' at (368, 281) conf: 47\n",
      "  164: 'of' at (401, 282) conf: 47\n",
      "  165: 'address)' at (411, 281) conf: 49\n",
      "  166: '(a)' at (82, 297) conf: 89\n",
      "  167: 'Address:' at (101, 297) conf: 72\n",
      "  168: 'Care' at (167, 297) conf: 50\n",
      "  169: 'of' at (196, 297) conf: 90\n",
      "  170: '(opional):' at (211, 297) conf: 45\n",
      "  171: 'T' at (66, 83) conf: 77\n",
      "  172: 'House' at (82, 315) conf: 94\n",
      "  173: 'no,' at (120, 318) conf: 78\n",
      "  174: '/' at (139, 315) conf: 91\n",
      "  175: 'Building' at (147, 315) conf: 92\n",
      "  176: '/' at (196, 303) conf: 76\n",
      "  177: 'Flat' at (204, 315) conf: 76\n",
      "  178: 'no.' at (228, 318) conf: 87\n",
      "  179: 'Street' at (387, 315) conf: 82\n",
      "  180: 'Landmark:' at (78, 321) conf: 89\n",
      "  181: 'Area/Locality/Sector:' at (387, 333) conf: 44\n",
      "  182: 'Village/Town/City:' at (82, 340) conf: 55\n",
      "  183: 'Post' at (320, 352) conf: 95\n",
      "  184: 'Office' at (346, 352) conf: 71\n",
      "  185: 'PIN' at (549, 352) conf: 96\n",
      "  186: 'code' at (573, 352) conf: 96\n",
      "  187: 'Suib-district:' at (82, 358) conf: 38\n",
      "  188: 'District:' at (320, 358) conf: 47\n",
      "  189: 'State:' at (549, 370) conf: 88\n",
      "  190: 'Type' at (102, 389) conf: 96\n",
      "  191: 'of' at (134, 389) conf: 96\n",
      "  192: 'documents' at (149, 389) conf: 88\n",
      "  193: 'presented:' at (214, 389) conf: 88\n",
      "  194: '(i)' at (315, 389) conf: 71\n",
      "  195: 'Proof' at (331, 389) conf: 96\n",
      "  196: 'of' at (364, 377) conf: 72\n",
      "  197: 'Identity' at (380, 389) conf: 72\n",
      "  198: '(POD:' at (423, 389) conf: 60\n",
      "  199: 'ee' at (103, 403) conf: 35\n",
      "  200: '(ii)' at (315, 408) conf: 81\n",
      "  201: 'Proof' at (335, 407) conf: 90\n",
      "  202: 'of' at (367, 402) conf: 96\n",
      "  203: 'Address' at (384, 407) conf: 93\n",
      "  204: '(POA):' at (429, 407) conf: 93\n",
      "  205: 'displayed' at (157, 414) conf: 47\n",
      "  206: 'onthe' at (202, 415) conf: 81\n",
      "  207: 'website' at (231, 415) conf: 51\n",
      "  208: 'of' at (266, 415) conf: 51\n",
      "  209: 'ee' at (104, 428) conf: 32\n",
      "  210: '(az)' at (315, 425) conf: 44\n",
      "  211: 'Proof' at (341, 415) conf: 96\n",
      "  212: 'of' at (372, 425) conf: 93\n",
      "  213: 'Datc' at (388, 425) conf: 77\n",
      "  214: 'of' at (415, 425) conf: 96\n",
      "  215: 'Birth' at (431, 415) conf: 40\n",
      "  216: '(PDB)' at (460, 425) conf: 87\n",
      "✅ Loaded Arial font\n",
      "\n",
      "📝 Filling form fields...\n",
      "\n",
      "🔍 Looking for field: Name (value: Elon Musk)\n",
      "  🎯 Found label 'Name:' for keyword 'name'\n",
      "  ✅ Filling 'Name' at position (147, 129)\n",
      "\n",
      "🔍 Looking for field: Aadhaar Number (value: 4567 8901 2345)\n",
      "  🎯 Found label 'Aadhaar' for keyword 'aadhaar'\n",
      "  ✅ Filling 'Aadhaar Number' at position (423, 30)\n",
      "\n",
      "🔍 Looking for field: Date of Birth (value: 28/06/1971)\n",
      "  🎯 Found label 'Birth:' for keyword 'birth'\n",
      "  ✅ Filling 'Date of Birth' at position (366, 173)\n",
      "\n",
      "🔍 Looking for field: Gender (value: Male)\n",
      "  🎯 Found label 'Gender:' for keyword 'gender'\n",
      "  ✅ Filling 'Gender' at position (225, 172)\n",
      "\n",
      "🔍 Looking for field: Address (value: 789, Space Colony)\n",
      "  🎯 Found label 'Address' for keyword 'address'\n",
      "  ✅ Filling 'Address' at position (555, 48)\n",
      "\n",
      "🎉 Successfully filled 5 out of 5 fields\n",
      "✅ Form filled and saved at: D:\\Form_automation\\Output\\filled_form.jpg\n",
      "\n",
      "📊 Summary:\n",
      "  • Extracted 5 fields from Aadhaar\n",
      "  • Detected 217 text blocks in form\n",
      "  • Successfully filled 5 fields\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "# ----------------------------\n",
    "# Step 0: Setup Tesseract Path\n",
    "# ----------------------------\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\T077\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data (Your existing code - working fine)\n",
    "# ----------------------------\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "\n",
    "print(f\"📄 Extracted text from Aadhaar: {all_text}\")\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract data\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction (all lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: only next 2 lines after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1 : dob_index + 3]\n",
    "    cleaned_address_lines = []\n",
    "    for line in address_candidates:\n",
    "        line = re.sub(r'\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b', '', line)\n",
    "        if line.strip():\n",
    "            cleaned_address_lines.append(line.strip())\n",
    "    address = \" \".join(cleaned_address_lines) if cleaned_address_lines else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"✅ Extracted Aadhaar Data:\")\n",
    "print(json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: FIXED Form Field Detection using Tesseract directly\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "\n",
    "def detect_form_fields_improved(image_path):\n",
    "    \"\"\"Improved form field detection using multiple methods\"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    \n",
    "    # Convert to RGB for PIL\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "    \n",
    "    # Method 1: Use Tesseract to get text with bounding boxes\n",
    "    print(\"🔍 Detecting form fields using Tesseract...\")\n",
    "    \n",
    "    # Get detailed OCR data\n",
    "    ocr_data = pytesseract.image_to_data(pil_img, output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    text_blocks = []\n",
    "    for i in range(len(ocr_data['text'])):\n",
    "        text = ocr_data['text'][i].strip()\n",
    "        conf = ocr_data['conf'][i]\n",
    "        \n",
    "        if text and conf > 30:  # Only consider confident detections\n",
    "            x, y, w, h = ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i]\n",
    "            text_blocks.append({\n",
    "                'text': text,\n",
    "                'confidence': conf,\n",
    "                'bbox': (x, y, x + w, y + h),\n",
    "                'x1': x, 'y1': y, 'x2': x + w, 'y2': y + h\n",
    "            })\n",
    "    \n",
    "    print(f\"📋 Found {len(text_blocks)} text blocks in form\")\n",
    "    \n",
    "    # Debug: Print all detected text\n",
    "    print(\"🔤 Detected text blocks:\")\n",
    "    for i, block in enumerate(text_blocks):\n",
    "        print(f\"  {i}: '{block['text']}' at ({block['x1']}, {block['y1']}) conf: {block['confidence']}\")\n",
    "    \n",
    "    return text_blocks, pil_img\n",
    "\n",
    "def find_field_fill_position(text_blocks, field_keywords):\n",
    "    \"\"\"Find the best position to fill a field based on label detection\"\"\"\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        text_lower = block['text'].lower().strip()\n",
    "        \n",
    "        # Check if this block contains any of our field keywords\n",
    "        for keyword in field_keywords:\n",
    "            if keyword.lower() in text_lower:\n",
    "                print(f\"  🎯 Found label '{block['text']}' for keyword '{keyword}'\")\n",
    "                \n",
    "                # Strategy 1: Look for colon and fill after it\n",
    "                if ':' in block['text']:\n",
    "                    # Fill right after the colon in the same block\n",
    "                    return block['x2'] + 10, block['y1']\n",
    "                \n",
    "                # Strategy 2: Look for underscore or line after the label\n",
    "                # Find text blocks that are on the same line (similar y coordinate)\n",
    "                same_line_blocks = []\n",
    "                for other_block in text_blocks:\n",
    "                    if abs(other_block['y1'] - block['y1']) < 15:  # Same line tolerance\n",
    "                        same_line_blocks.append(other_block)\n",
    "                \n",
    "                # Sort by x coordinate\n",
    "                same_line_blocks.sort(key=lambda x: x['x1'])\n",
    "                \n",
    "                # Find our label block in the sorted list\n",
    "                label_index = -1\n",
    "                for i, same_block in enumerate(same_line_blocks):\n",
    "                    if same_block['text'] == block['text']:\n",
    "                        label_index = i\n",
    "                        break\n",
    "                \n",
    "                # Look for space after the label\n",
    "                if label_index >= 0 and label_index < len(same_line_blocks) - 1:\n",
    "                    next_block = same_line_blocks[label_index + 1]\n",
    "                    # If there's a significant gap, fill in that gap\n",
    "                    if next_block['x1'] - block['x2'] > 50:\n",
    "                        return block['x2'] + 20, block['y1']\n",
    "                    # If next block might be an underscore or line, fill over it\n",
    "                    elif '_' in next_block['text'] or '___' in next_block['text']:\n",
    "                        return next_block['x1'] + 5, next_block['y1']\n",
    "                \n",
    "                # Strategy 3: Default - fill to the right of the label\n",
    "                return block['x2'] + 20, block['y1']\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Detect form fields\n",
    "text_blocks, form_img = detect_form_fields_improved(form_image_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: FIXED Form Filling Logic\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "\n",
    "# Try to load font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    print(\"✅ Loaded Arial font\")\n",
    "except:\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"calibri.ttf\", 20)\n",
    "        print(\"✅ Loaded Calibri font\")\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        print(\"⚠️ Using default font\")\n",
    "\n",
    "# Enhanced label mapping with multiple variations\n",
    "field_keywords = {\n",
    "    \"Name\": [\"name\", \"full name\", \"applicant name\", \"person name\", \"naam\"],\n",
    "    \"Aadhaar Number\": [\"aadhaar\", \"aadhar\", \"aadhaar number\", \"aadhar number\", \"uid\", \"unique id\"],\n",
    "    \"Date of Birth\": [\"date of birth\", \"dob\", \"birth date\", \"date birth\", \"birth\"],\n",
    "    \"Gender\": [\"gender\", \"sex\", \"male/female\", \"m/f\"],\n",
    "    \"Address\": [\"address\", \"residence\", \"location\", \"home address\", \"present address\"]\n",
    "}\n",
    "\n",
    "print(\"\\n📝 Filling form fields...\")\n",
    "\n",
    "filled_count = 0\n",
    "\n",
    "# Try to fill each field\n",
    "for field_name, field_value in form_data.items():\n",
    "    if field_value:  # Only fill if we have data\n",
    "        print(f\"\\n🔍 Looking for field: {field_name} (value: {field_value})\")\n",
    "        \n",
    "        # Get keywords for this field\n",
    "        keywords = field_keywords.get(field_name, [field_name.lower()])\n",
    "        \n",
    "        # Find position to fill\n",
    "        position = find_field_fill_position(text_blocks, keywords)\n",
    "        \n",
    "        if position:\n",
    "            x, y = position\n",
    "            print(f\"  ✅ Filling '{field_name}' at position ({x}, {y})\")\n",
    "            \n",
    "            # Draw the value\n",
    "            draw.text((x, y), str(field_value), fill=\"blue\", font=font)\n",
    "            filled_count += 1\n",
    "        else:\n",
    "            print(f\"  ❌ Could not find position for '{field_name}'\")\n",
    "\n",
    "print(f\"\\n🎉 Successfully filled {filled_count} out of {len([v for v in form_data.values() if v])} fields\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Save Filled Form with Debug Info\n",
    "# ----------------------------\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "\n",
    "# Optional: Draw debug rectangles around detected text blocks\n",
    "debug_mode = True  # Set to False to disable debug rectangles\n",
    "\n",
    "if debug_mode:\n",
    "    print(\"\\n🐛 Adding debug rectangles...\")\n",
    "    debug_draw = ImageDraw.Draw(form_img)\n",
    "    \n",
    "    for i, block in enumerate(text_blocks):\n",
    "        x1, y1, x2, y2 = block['bbox']\n",
    "        # Draw red rectangle around detected text\n",
    "        debug_draw.rectangle([x1-1, y1-1, x2+1, y2+1], outline=\"red\", width=1)\n",
    "        # Add small text with block number\n",
    "        debug_draw.text((x1, y1-15), str(i), fill=\"red\", font=font)\n",
    "\n",
    "# form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Additional Debugging Information\n",
    "# ----------------------------\n",
    "print(\"\\n📊 Summary:\")\n",
    "print(f\"  • Extracted {len([v for v in form_data.values() if v])} fields from Aadhaar\")\n",
    "print(f\"  • Detected {len(text_blocks)} text blocks in form\")\n",
    "print(f\"  • Successfully filled {filled_count} fields\")\n",
    "\n",
    "if filled_count == 0:\n",
    "    print(\"\\n🔧 Troubleshooting tips:\")\n",
    "    print(\"  1. Check if the form image is clear and readable\")\n",
    "    print(\"  2. Verify that field labels match the expected keywords\")\n",
    "    print(\"  3. Try adjusting the confidence threshold (currently 30)\")\n",
    "    print(\"  4. Check if debug rectangles appear around text in the output image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\T077\\anaconda3\\envs\\form_auto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Extracted text from Aadhaar: ATTT TET GOVERNMENT OF INDIA AADAAAR Elon Musk Male 28/06/1971 789, Space Colony 4567 8901 2345 AT 31renr; A 48TT\n",
      "✅ Extracted Aadhaar Data:\n",
      "{\n",
      "    \"Name\": \"Elon Musk\",\n",
      "    \"Aadhaar Number\": \"4567 8901 2345\",\n",
      "    \"Date of Birth\": \"28/06/1971\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Address\": \"789, Space Colony\"\n",
      "}\n",
      "✅ Form filled and saved at: D:\\Form_automation\\Output\\filled_form.jpg\n",
      "🎉 Successfully filled 5 fields out of 5\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "# ----------------------------\n",
    "# Step 0: Setup Tesseract Path\n",
    "# ----------------------------\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\T077\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Extract Aadhaar Data\n",
    "# ----------------------------\n",
    "aadhaar_image_path = r\"D:\\Form_automation\\Aadhar_pic\\WhatsApp-Image-2025-04-05-at-1.57.04-PM.jpeg\"\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "results = reader.readtext(aadhaar_image_path)\n",
    "lines = [text.strip() for _, text, _ in results]\n",
    "all_text = \" \".join(lines)\n",
    "print(f\"📄 Extracted text from Aadhaar: {all_text}\")\n",
    "\n",
    "# Regex patterns\n",
    "aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "\n",
    "# Extract data\n",
    "aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "dob_match = re.search(dob_pattern, all_text)\n",
    "gender = re.search(gender_pattern, all_text)\n",
    "\n",
    "# Name extraction (lines above DOB)\n",
    "name = None\n",
    "dob_index = None\n",
    "if dob_match:\n",
    "    dob_text = dob_match.group()\n",
    "    dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "    if dob_index is not None:\n",
    "        candidate_lines = lines[:dob_index]\n",
    "        headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "        cleaned_lines = []\n",
    "        for line in candidate_lines:\n",
    "            line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "            for header in headers:\n",
    "                line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "            if line.strip():\n",
    "                cleaned_lines.append(line.strip())\n",
    "        merged_text = \" \".join(cleaned_lines)\n",
    "        doc = nlp(merged_text)\n",
    "        person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "        if person_names:\n",
    "            name = \" \".join(person_names)\n",
    "        else:\n",
    "            tokens = merged_text.split()\n",
    "            if tokens:\n",
    "                name = \" \".join(tokens[:2])\n",
    "\n",
    "# Address: only next 2 lines after DOB\n",
    "address = None\n",
    "if dob_index is not None:\n",
    "    address_candidates = lines[dob_index + 1 : dob_index + 3]\n",
    "    cleaned_address_lines = []\n",
    "    for line in address_candidates:\n",
    "        line = re.sub(r'\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b', '', line)\n",
    "        if line.strip():\n",
    "            cleaned_address_lines.append(line.strip())\n",
    "    address = \" \".join(cleaned_address_lines) if cleaned_address_lines else None\n",
    "\n",
    "form_data = {\n",
    "    \"Name\": name,\n",
    "    \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "    \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "    \"Gender\": gender.group() if gender else None,\n",
    "    \"Address\": address\n",
    "}\n",
    "\n",
    "print(\"✅ Extracted Aadhaar Data:\")\n",
    "print(json.dumps(form_data, indent=4))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Detect Form Fields using Tesseract\n",
    "# ----------------------------\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "\n",
    "def detect_form_fields_improved(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "\n",
    "    ocr_data = pytesseract.image_to_data(pil_img, output_type=pytesseract.Output.DICT)\n",
    "    text_blocks = []\n",
    "    for i in range(len(ocr_data['text'])):\n",
    "        text = ocr_data['text'][i].strip()\n",
    "        conf = int(ocr_data['conf'][i])\n",
    "        if text and conf > 30:\n",
    "            x, y, w, h = ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i]\n",
    "            text_blocks.append({\n",
    "                'text': text,\n",
    "                'confidence': conf,\n",
    "                'bbox': (x, y, x + w, y + h),\n",
    "                'x1': x, 'y1': y, 'x2': x + w, 'y2': y + h\n",
    "            })\n",
    "    return text_blocks, pil_img\n",
    "\n",
    "def find_field_fill_position(text_blocks, field_keywords):\n",
    "    for block in text_blocks:\n",
    "        text_lower = block['text'].lower().strip()\n",
    "        for keyword in field_keywords:\n",
    "            if keyword.lower() in text_lower:\n",
    "                # Strategy 1: fill after colon\n",
    "                if ':' in block['text']:\n",
    "                    return block['x2'] + 10, block['y1']\n",
    "                # Strategy 2: check line after label\n",
    "                same_line_blocks = [b for b in text_blocks if abs(b['y1'] - block['y1']) < 15]\n",
    "                same_line_blocks.sort(key=lambda x: x['x1'])\n",
    "                label_index = next((i for i, b in enumerate(same_line_blocks) if b['text'] == block['text']), -1)\n",
    "                if label_index >= 0 and label_index < len(same_line_blocks) - 1:\n",
    "                    next_block = same_line_blocks[label_index + 1]\n",
    "                    if next_block['x1'] - block['x2'] > 50 or '_' in next_block['text']:\n",
    "                        return block['x2'] + 20, block['y1']\n",
    "                return block['x2'] + 20, block['y1']\n",
    "    return None\n",
    "\n",
    "# Detect form fields\n",
    "text_blocks, form_img = detect_form_fields_improved(form_image_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Fill Form Fields\n",
    "# ----------------------------\n",
    "draw = ImageDraw.Draw(form_img)\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "except:\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"calibri.ttf\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "field_keywords = {\n",
    "    \"Name\": [\"name\", \"full name\", \"applicant name\", \"person name\", \"naam\"],\n",
    "    \"Aadhaar Number\": [\"aadhaar\", \"aadhar\", \"aadhaar number\", \"aadhar number\", \"uid\", \"unique id\"],\n",
    "    \"Date of Birth\": [\"date of birth\", \"dob\", \"birth date\", \"date birth\", \"birth\"],\n",
    "    \"Gender\": [\"gender\", \"sex\", \"male/female\", \"m/f\"],\n",
    "    \"Address\": [\"address\", \"residence\", \"location\", \"home address\", \"present address\"]\n",
    "}\n",
    "\n",
    "filled_count = 0\n",
    "for field_name, field_value in form_data.items():\n",
    "    if field_value:\n",
    "        keywords = field_keywords.get(field_name, [field_name.lower()])\n",
    "        position = find_field_fill_position(text_blocks, keywords)\n",
    "        if position:\n",
    "            x, y = position\n",
    "            draw.text((x, y), str(field_value), fill=\"blue\", font=font)\n",
    "            filled_count += 1\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Save Filled Form (NO RED DEBUG BOXES)\n",
    "# ----------------------------\n",
    "output_path = r\"D:\\Form_automation\\Output\\filled_form.jpg\"\n",
    "form_img.save(output_path)\n",
    "print(f\"✅ Form filled and saved at: {output_path}\")\n",
    "print(f\"🎉 Successfully filled {filled_count} fields out of {len([v for v in form_data.values() if v])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import easyocr\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize OCR and NLP\n",
    "reader = easyocr.Reader(['en'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create upload folder\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('aadhaar_form.html')  # Render HTML page\n",
    "\n",
    "@app.route('/extract_aadhaar', methods=['POST'])\n",
    "def extract_aadhaar():\n",
    "    if 'aadhaar_image' not in request.files:\n",
    "        return jsonify({\"error\": \"No image uploaded\"}), 400\n",
    "    \n",
    "    image = request.files['aadhaar_image']\n",
    "    image_path = os.path.join(UPLOAD_FOLDER, image.filename)\n",
    "    image.save(image_path)\n",
    "    \n",
    "    # OCR extraction using EasyOCR\n",
    "    results = reader.readtext(image_path)\n",
    "    lines = [text.strip() for _, text, _ in results]\n",
    "    all_text = \" \".join(lines)\n",
    "    print(all_text)\n",
    "    # Regex patterns\n",
    "    aadhaar_pattern = r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\"\n",
    "    dob_pattern = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
    "    gender_pattern = r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\"\n",
    "    \n",
    "    aadhaar_number = re.search(aadhaar_pattern, all_text)\n",
    "    dob_match = re.search(dob_pattern, all_text)\n",
    "    gender = re.search(gender_pattern, all_text)\n",
    "    \n",
    "    # Extract Name\n",
    "    name = None\n",
    "    if dob_match:\n",
    "        dob_text = dob_match.group()\n",
    "        dob_index = next((i for i, line in enumerate(lines) if dob_text in line), None)\n",
    "        if dob_index is not None:\n",
    "            candidate_lines = lines[:dob_index]\n",
    "            headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "            cleaned_lines = []\n",
    "            for line in candidate_lines:\n",
    "                line = re.sub(r\"\\b(MALE|FEMALE|Male|Female|F|M)\\b\", \"\", line)\n",
    "                for header in headers:\n",
    "                    line = re.sub(header, \"\", line, flags=re.IGNORECASE)\n",
    "                if line.strip():\n",
    "                    cleaned_lines.append(line.strip())\n",
    "            merged_text = \" \".join(cleaned_lines)\n",
    "            doc = nlp(merged_text)\n",
    "            person_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "            name = \" \".join(person_names) if person_names else \" \".join(merged_text.split()[:2])\n",
    "    \n",
    "    # Extract Address (lines after DOB)\n",
    "    address = None\n",
    "    if dob_match:\n",
    "        dob_index = next((i for i, line in enumerate(lines) if dob_match.group() in line), None)\n",
    "        if dob_index is not None:\n",
    "            address_candidates = lines[dob_index + 1: dob_index + 3]\n",
    "            cleaned_address = [re.sub(r'\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b', '', line) for line in address_candidates if line.strip()]\n",
    "            address = \" \".join(cleaned_address)\n",
    "    \n",
    "    # Prepare response\n",
    "    data = {\n",
    "        \"Name\": name,\n",
    "        \"Aadhaar Number\": aadhaar_number.group() if aadhaar_number else None,\n",
    "        \"Date of Birth\": dob_match.group() if dob_match else None,\n",
    "        \"Gender\": gender.group() if gender else None,\n",
    "        \"Address\": address\n",
    "    }\n",
    "    \n",
    "    return jsonify(data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data', [Model(id='meta-llama/llama-guard-4-12b', created=1746743847, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=1024), Model(id='llama3-70b-8192', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None, max_completion_tokens=8192), Model(id='openai/gpt-oss-120b', created=1754408224, object='model', owned_by='OpenAI', active=True, context_window=131072, public_apps=None, max_completion_tokens=65536), Model(id='distil-whisper-large-v3-en', created=1693721698, object='model', owned_by='Hugging Face', active=True, context_window=448, public_apps=None, max_completion_tokens=448), Model(id='whisper-large-v3-turbo', created=1728413088, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None, max_completion_tokens=448), Model(id='deepseek-r1-distill-llama-70b', created=1737924940, object='model', owned_by='DeepSeek / Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=131072), Model(id='llama-3.1-8b-instant', created=1693721698, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=131072), Model(id='playai-tts-arabic', created=1740682783, object='model', owned_by='PlayAI', active=True, context_window=8192, public_apps=None, max_completion_tokens=8192), Model(id='compound-beta-mini', created=1742953279, object='model', owned_by='Groq', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='whisper-large-v3', created=1693721698, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None, max_completion_tokens=448), Model(id='gemma2-9b-it', created=1693721698, object='model', owned_by='Google', active=True, context_window=8192, public_apps=None, max_completion_tokens=8192), Model(id='meta-llama/llama-4-scout-17b-16e-instruct', created=1743874824, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='openai/gpt-oss-20b', created=1754407957, object='model', owned_by='OpenAI', active=True, context_window=131072, public_apps=None, max_completion_tokens=65536), Model(id='allam-2-7b', created=1737672203, object='model', owned_by='SDAIA', active=True, context_window=4096, public_apps=None, max_completion_tokens=4096), Model(id='moonshotai/kimi-k2-instruct', created=1752435491, object='model', owned_by='Moonshot AI', active=True, context_window=131072, public_apps=None, max_completion_tokens=16384), Model(id='playai-tts', created=1740682771, object='model', owned_by='PlayAI', active=True, context_window=8192, public_apps=None, max_completion_tokens=8192), Model(id='compound-beta', created=1740880017, object='model', owned_by='Groq', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='meta-llama/llama-4-maverick-17b-128e-instruct', created=1743877158, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='meta-llama/llama-prompt-guard-2-86m', created=1748632165, object='model', owned_by='Meta', active=True, context_window=512, public_apps=None, max_completion_tokens=512), Model(id='meta-llama/llama-prompt-guard-2-22m', created=1748632101, object='model', owned_by='Meta', active=True, context_window=512, public_apps=None, max_completion_tokens=512), Model(id='qwen/qwen3-32b', created=1748396646, object='model', owned_by='Alibaba Cloud', active=True, context_window=131072, public_apps=None, max_completion_tokens=40960), Model(id='llama3-8b-8192', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None, max_completion_tokens=8192), Model(id='llama-3.3-70b-versatile', created=1733447754, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=32768)])\n",
      "('object', 'list')\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "# List all available models\n",
    "models = client.models.list()\n",
    "for m in models:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\t077\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: easyocr in c:\\users\\t077\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Collecting groq\n",
      "  Using cached groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: torch in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (0.23.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (4.7.0.72)\n",
      "Requirement already satisfied: scipy in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (1.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (2.3.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (10.4.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (0.6.6)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (6.0.1)\n",
      "Requirement already satisfied: Shapely in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (2.1.1)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr) (1.13.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\t077\\anaconda3\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from groq) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\t077\\anaconda3\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\t077\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\t077\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr) (75.1.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
      "Using cached groq-0.31.0-py3-none-any.whl (131 kB)\n",
      "Installing collected packages: groq\n",
      "Successfully installed groq-0.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flask easyocr groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.4.0-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Downloading mysql_connector_python-9.4.0-cp312-cp312-win_amd64.whl (16.4 MB)\n",
      "   ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 10.2/16.4 MB 53.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.4/16.4 MB 49.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import easyocr\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from werkzeug.utils import secure_filename\n",
    "import mysql.connector  # ✅ Added for DB\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize OCR\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp'}\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "# Configure upload settings\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# ✅ Database connection\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"your_password\",  # Change this\n",
    "    database=\"aadhaar_db\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Initialize Groq client\n",
    "try:\n",
    "    client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    print(\"✅ Groq API client initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing Groq client: {e}\")\n",
    "    client = None\n",
    "\n",
    "def allowed_file(filename):\n",
    "    \"\"\"Check if file extension is allowed\"\"\"\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def extract_aadhaar_data_locally(text):\n",
    "    \"\"\"Fallback function to extract Aadhaar data using regex (if Groq fails)\"\"\"\n",
    "    print(\"🔧 Using local extraction as fallback...\")\n",
    "    \n",
    "    # Clean the text\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    \n",
    "    # Extract patterns\n",
    "    patterns = {\n",
    "        'aadhaar_number': r'\\b\\d{4}\\s?\\d{4}\\s?\\d{4}\\b',\n",
    "        'date_of_birth': r'\\b\\d{2}/\\d{2}/\\d{4}\\b',\n",
    "        'gender': r'\\b(MALE|FEMALE|Male|Female|M|F)\\b'\n",
    "    }\n",
    "    \n",
    "    extracted = {}\n",
    "    \n",
    "    # Extract using patterns\n",
    "    for field, pattern in patterns.items():\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            extracted[field] = match.group()\n",
    "    \n",
    "    # Simple name extraction (improve as needed)\n",
    "    words = text.split()\n",
    "    # Remove common Aadhaar card headers\n",
    "    headers = [\"GOVERNMENT\", \"INDIA\", \"AADHAAR\", \"UNIQUE\", \"IDENTIFICATION\", \"AUTHORITY\", \"OF\"]\n",
    "    clean_words = [word for word in words if word.upper() not in headers and word.isalpha() and len(word) > 2]\n",
    "    \n",
    "    # Take first 2-3 words as name\n",
    "    name = \" \".join(clean_words[:3]) if clean_words else \"\"\n",
    "    \n",
    "    # Simple address extraction (last few meaningful words)\n",
    "    address_words = [word for word in words[-10:] if not re.match(r'\\d{4}\\s?\\d{4}\\s?\\d{4}', word)]\n",
    "    address = \" \".join(address_words) if address_words else \"\"\n",
    "    \n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"aadhaar_number\": extracted.get('aadhaar_number', ''),\n",
    "        \"date_of_birth\": extracted.get('date_of_birth', ''),\n",
    "        \"gender\": extracted.get('gender', ''),\n",
    "        \"address\": address\n",
    "    }\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Serve the main form page\"\"\"\n",
    "    try:\n",
    "        return render_template('aadhaar_form.html')\n",
    "    except Exception as e:\n",
    "        return f\"Error loading template: {e}\", 500\n",
    "\n",
    "@app.route('/extract_aadhaar', methods=['POST'])\n",
    "def extract_aadhaar():\n",
    "    \"\"\"Extract Aadhaar details from uploaded images\"\"\"\n",
    "    try:\n",
    "        print(\"📤 Received request to extract Aadhaar data\")\n",
    "        \n",
    "        # Check if files were uploaded\n",
    "        if 'aadhaar_images' not in request.files:\n",
    "            return jsonify({\"error\": \"No images uploaded\"}), 400\n",
    "        \n",
    "        files = request.files.getlist('aadhaar_images')\n",
    "        if not files or all(file.filename == '' for file in files):\n",
    "            return jsonify({\"error\": \"No images selected\"}), 400\n",
    "        \n",
    "        combined_text = \"\"\n",
    "        processed_files = []\n",
    "        \n",
    "        # Process each uploaded image\n",
    "        for image in files:\n",
    "            if image and allowed_file(image.filename):\n",
    "                # Secure filename\n",
    "                filename = secure_filename(image.filename)\n",
    "                image_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "                \n",
    "                # Save image\n",
    "                image.save(image_path)\n",
    "                processed_files.append(image_path)\n",
    "                \n",
    "                print(f\"📸 Processing image: {filename}\")\n",
    "                \n",
    "                # Extract text using EasyOCR\n",
    "                try:\n",
    "                    results = reader.readtext(image_path)\n",
    "                    text = \" \".join([detection[1] for detection in results])\n",
    "                    combined_text += \" \" + text\n",
    "                    print(f\"📄 Extracted text: {text[:100]}...\")\n",
    "                except Exception as ocr_error:\n",
    "                    print(f\"❌ OCR Error for {filename}: {ocr_error}\")\n",
    "                    continue\n",
    "             \n",
    "        if not combined_text.strip():\n",
    "            return jsonify({\"error\": \"No text could be extracted from images\"}), 400\n",
    "        \n",
    "        print(f\"🔤 Combined text length: {len(combined_text)} characters\")\n",
    "        \n",
    "        # Try to use Groq LLM for extraction\n",
    "        extracted_data = None\n",
    "        \n",
    "        if client:\n",
    "            try:\n",
    "                print(\"🤖 Using Groq LLM for data extraction...\")\n",
    "                \n",
    "                prompt = f\"\"\"\n",
    "You are an expert at extracting information from Indian Aadhaar cards. \n",
    "\n",
    "IMPORTANT CONTEXT about Aadhaar cards:\n",
    "- The cardholder's name appears prominently at the top\n",
    "- Father's/Husband's name appears below with prefixes like \"S/O\" (Son Of), \"D/O\" (Daughter Of), \"W/O\" (Wife Of), \"Father:\", \"Husband:\"\n",
    "- The cardholder's name is usually in larger font and appears first\n",
    "- Father's/Husband's name is secondary information\n",
    "\n",
    "Text from Aadhaar card: {combined_text}\n",
    "\n",
    "Extract the following information and return ONLY valid JSON:\n",
    "\n",
    "Required fields:\n",
    "- name: The CARDHOLDER's name (NOT father's/husband's name). This is the primary name, usually appears first and largest. Ignore any name that comes after S/O, D/O, W/O, Father:, or Husband:\n",
    "- aadhaar_number: 12-digit number (format: XXXX XXXX XXXX)\n",
    "- date_of_birth: Date in DD/MM/YYYY format\n",
    "- gender: Male/Female/Other\n",
    "- address: Complete address excluding Aadhaar number\n",
    "\n",
    "EXTRACTION RULES:\n",
    "1. For NAME: Take the name that appears BEFORE any of these indicators: \"S/O\", \"D/O\", \"W/O\", \"Father\", \"Husband\", \"Son of\", \"Daughter of\", \"Wife of\"\n",
    "2. Skip any text that contains government headers like \"GOVERNMENT OF INDIA\", \"AADHAAR\", \"UNIQUE IDENTIFICATION\"\n",
    "3. The correct name is usually the first meaningful name that appears after removing headers\n",
    "4. If you see multiple names, the cardholder's name comes first, parent/spouse name comes after relationship indicators\n",
    "\n",
    "Return only valid JSON:\n",
    "{{\n",
    "    \"name\": \"actual_cardholder_name_here\",\n",
    "    \"aadhaar_number\": \"XXXX XXXX XXXX\",\n",
    "    \"date_of_birth\": \"DD/MM/YYYY\",\n",
    "    \"gender\": \"Male/Female/Other\",\n",
    "    \"address\": \"complete_address_here\"\n",
    "}}\n",
    "\"\"\"\n",
    "                \n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"llama-3.3-70b-versatile\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\", \n",
    "                            \"content\": \"You are an expert at extracting structured data from Indian Aadhaar cards. Always return valid JSON only.\"\n",
    "                        },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.1,\n",
    "                    max_tokens=500\n",
    "                )\n",
    "                \n",
    "                # Get the response content\n",
    "                llm_response = response.choices[0].message.content.strip()\n",
    "                print(f\"🤖 LLM Response: {llm_response}\")\n",
    "                \n",
    "                # Try to parse JSON from LLM response\n",
    "                try:\n",
    "                    # Clean the response (remove any markdown formatting)\n",
    "                    if '```json' in llm_response:\n",
    "                        llm_response = llm_response.split('```json')[1].split('```')[0].strip()\n",
    "                    elif '```' in llm_response:\n",
    "                        llm_response = llm_response.split('```')[1].strip()\n",
    "                    \n",
    "                    extracted_data = json.loads(llm_response)\n",
    "                    print(\"✅ Successfully parsed LLM response\")\n",
    "                    \n",
    "                except json.JSONDecodeError as json_error:\n",
    "                    print(f\"❌ JSON parsing error: {json_error}\")\n",
    "                    print(f\"Raw response: {llm_response}\")\n",
    "                    extracted_data = None\n",
    "                    \n",
    "            except Exception as groq_error:\n",
    "                print(f\"❌ Groq API Error: {groq_error}\")\n",
    "                extracted_data = None\n",
    "        \n",
    "        # Fallback to local extraction if Groq fails\n",
    "        if not extracted_data:\n",
    "            print(\"🔄 Falling back to local regex extraction...\")\n",
    "            extracted_data = extract_aadhaar_data_locally(combined_text)\n",
    "        \n",
    "        # ✅ Insert into Database\n",
    "        try:\n",
    "            sql = \"\"\"INSERT INTO aadhaar_details (name, aadhaar_number, date_of_birth, gender, address) \n",
    "                     VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "            values = (\n",
    "                extracted_data.get(\"name\", \"\"),\n",
    "                extracted_data.get(\"aadhaar_number\", \"\"),\n",
    "                extracted_data.get(\"date_of_birth\", \"\"),\n",
    "                extracted_data.get(\"gender\", \"\"),\n",
    "                extracted_data.get(\"address\", \"\")\n",
    "            )\n",
    "            cursor.execute(sql, values)\n",
    "            db.commit()\n",
    "            print(\"✅ Data saved in database\")\n",
    "        except Exception as db_error:\n",
    "            print(f\"❌ Database Error: {db_error}\")\n",
    "        \n",
    "        # Clean up uploaded files (optional)\n",
    "        for file_path in processed_files:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"✅ Final extracted data: {extracted_data}\")\n",
    "        return jsonify(extracted_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ General Error: {e}\")\n",
    "        return jsonify({\"error\": f\"Server error: {str(e)}\"}), 500\n",
    "\n",
    "@app.route('/health')\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        \"status\": \"healthy\",\n",
    "        \"groq_available\": client is not None,\n",
    "        \"upload_folder\": os.path.exists(UPLOAD_FOLDER)\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"🚀 Starting Aadhaar Form Automation Server...\")\n",
    "    print(f\"📁 Upload folder: {UPLOAD_FOLDER}\")\n",
    "    print(f\"🤖 Groq API: {'Available' if client else 'Not available'}\")\n",
    "    \n",
    "    # Create templates folder if it doesn't exist\n",
    "    templates_dir = os.path.join(app.root_path, 'templates')\n",
    "    if not os.path.exists(templates_dir):\n",
    "        os.makedirs(templates_dir)\n",
    "        print(f\"📂 Created templates directory: {templates_dir}\")\n",
    "    \n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pytesseract) (11.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: layoutparser[ocr] in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (2.2.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (4.12.0.88)\n",
      "Requirement already satisfied: scipy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (1.15.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (2.3.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (6.0.2)\n",
      "Requirement already satisfied: iopath in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (0.11.7)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from layoutparser[ocr]) (1.17.0)\n",
      "Collecting google-cloud-vision==1 (from layoutparser[ocr])\n",
      "  Downloading google_cloud_vision-1.0.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pytesseract (from layoutparser[ocr])\n",
      "  Using cached pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.14.0 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Downloading google_api_core-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2 (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-win_amd64.whl.metadata (698 bytes)\n",
      "Collecting google-auth<3.0dev,>=1.25.0 (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.32.5)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Downloading grpcio-1.74.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Downloading grpcio_status-1.74.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.61.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.5-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading grpcio_status-1.57.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.0rc2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.55.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.0rc2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.52.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.50.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.49.0rc3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading grpcio_status-1.49.0rc1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr]) (2025.8.3)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision==1->layoutparser[ocr])\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser[ocr]) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser[ocr]) (4.14.1)\n",
      "Requirement already satisfied: portalocker in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from iopath->layoutparser[ocr]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pandas->layoutparser[ocr]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pandas->layoutparser[ocr]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pandas->layoutparser[ocr]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->layoutparser[ocr]) (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfplumber->layoutparser[ocr]) (20250506)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfplumber->layoutparser[ocr]) (4.30.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber->layoutparser[ocr]) (45.0.6)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber->layoutparser[ocr]) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber->layoutparser[ocr]) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from portalocker->iopath->layoutparser[ocr]) (311)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pytesseract->layoutparser[ocr]) (25.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from tqdm->iopath->layoutparser[ocr]) (0.4.6)\n",
      "Downloading google_cloud_vision-1.0.0-py2.py3-none-any.whl (435 kB)\n",
      "Downloading google_api_core-1.34.1-py3-none-any.whl (120 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.74.0-cp310-cp310-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.5/4.5 MB 67.2 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.49.0rc1-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "   ---------------------------------------- 0.0/904.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 904.0/904.0 kB 40.1 MB/s eta 0:00:00\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract, pyasn1, protobuf, grpcio, cachetools, rsa, pyasn1-modules, googleapis-common-protos, grpcio-status, google-auth, google-api-core, google-cloud-vision\n",
      "\n",
      "   --- ------------------------------------  1/12 [pyasn1]\n",
      "   ------ ---------------------------------  2/12 [protobuf]\n",
      "   ---------- -----------------------------  3/12 [grpcio]\n",
      "   ---------- -----------------------------  3/12 [grpcio]\n",
      "   ------------- --------------------------  4/12 [cachetools]\n",
      "   -------------------- -------------------  6/12 [pyasn1-modules]\n",
      "   -------------------- -------------------  6/12 [pyasn1-modules]\n",
      "   -------------------- -------------------  6/12 [pyasn1-modules]\n",
      "   -------------------- -------------------  6/12 [pyasn1-modules]\n",
      "   ----------------------- ----------------  7/12 [googleapis-common-protos]\n",
      "   ----------------------- ----------------  7/12 [googleapis-common-protos]\n",
      "   ------------------------------ ---------  9/12 [google-auth]\n",
      "   ------------------------------ ---------  9/12 [google-auth]\n",
      "   --------------------------------- ------ 10/12 [google-api-core]\n",
      "   --------------------------------- ------ 10/12 [google-api-core]\n",
      "   ------------------------------------ --- 11/12 [google-cloud-vision]\n",
      "   ------------------------------------ --- 11/12 [google-cloud-vision]\n",
      "   ------------------------------------ --- 11/12 [google-cloud-vision]\n",
      "   ---------------------------------------- 12/12 [google-cloud-vision]\n",
      "\n",
      "Successfully installed cachetools-5.5.2 google-api-core-1.34.1 google-auth-2.40.3 google-cloud-vision-1.0.0 googleapis-common-protos-1.70.0 grpcio-1.74.0 grpcio-status-1.49.0rc1 protobuf-3.20.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pytesseract-0.3.13 rsa-4.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade layoutparser[ocr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import layoutparser as lp\n",
    "from layoutparser.ocr import TesseractAgent\n",
    "\n",
    "# Load form image\n",
    "form_image_path = r\"D:\\Form_automation\\Aadhar_pic\\Aadhaar-Form-1-1.jpg.webp\"\n",
    "form_img = Image.open(form_image_path).convert(\"RGB\")\n",
    "image_np = np.array(form_img)\n",
    "\n",
    "# Initialize Tesseract OCR\n",
    "ocr_agent = TesseractAgent(languages='eng')\n",
    "\n",
    "# Detect all text blocks\n",
    "layout = ocr_agent.detect(image_np)\n",
    "text_blocks = [b for b in layout if hasattr(b, \"type\") and b.type == \"Text\"]\n",
    "\n",
    "# Find the \"Name\" label\n",
    "name_block = None\n",
    "for block in text_blocks:\n",
    "    if \"name\" in block.text.strip().lower():\n",
    "        name_block = block\n",
    "        break\n",
    "\n",
    "if name_block:\n",
    "    # Get coordinates of the blank space near the label\n",
    "    # Usually we can assume writing starts a bit to the right of the label\n",
    "    x_start = int(name_block.block.x_2 + 10)  # right of label\n",
    "    y_start = int(name_block.block.y_1)\n",
    "    print(\"✅ Name field coordinates:\", x_start, y_start)\n",
    "\n",
    "    # Example: write the extracted name\n",
    "    draw = ImageDraw.Draw(form_img)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    extracted_name = \"Elon Musk\"\n",
    "    draw.text((x_start, y_start), extracted_name, fill=\"black\", font=font)\n",
    "\n",
    "# Save filled image\n",
    "form_img.save(r\"D:\\Form_automation\\Output\\filled_form_test.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\T077\\anaconda3\\envs\\form_auto\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.10\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.7.15  |       haa95532_0         127 KB\n",
      "    expat-2.7.1                |       h8ddb27b_0         259 KB\n",
      "    openssl-3.0.17             |       h35632f6_0         7.8 MB\n",
      "    pip-25.1                   |     pyhc872135_2         1.3 MB\n",
      "    python-3.10.18             |       h981015d_0        16.2 MB\n",
      "    setuptools-78.1.1          |  py310haa95532_0         1.7 MB\n",
      "    sqlite-3.50.2              |       hda9a48d_1        1017 KB\n",
      "    tk-8.6.15                  |       hf199647_0         3.5 MB\n",
      "    tzdata-2025b               |       h04d1e81_0         116 KB\n",
      "    ucrt-10.0.22621.0          |       haa95532_0         620 KB\n",
      "    vc-14.3                    |      h2df5915_10          19 KB\n",
      "    vc14_runtime-14.44.35208   |      h4927774_10         825 KB\n",
      "    vs2015_runtime-14.44.35208 |      ha6b5a95_10          19 KB\n",
      "    wheel-0.45.1               |  py310haa95532_0         145 KB\n",
      "    xz-5.6.4                   |       h4754444_1         280 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        33.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              pkgs/main/win-64::bzip2-1.0.8-h2bbff1b_6 \n",
      "  ca-certificates    pkgs/main/win-64::ca-certificates-2025.7.15-haa95532_0 \n",
      "  expat              pkgs/main/win-64::expat-2.7.1-h8ddb27b_0 \n",
      "  libffi             pkgs/main/win-64::libffi-3.4.4-hd77b12b_1 \n",
      "  openssl            pkgs/main/win-64::openssl-3.0.17-h35632f6_0 \n",
      "  pip                pkgs/main/noarch::pip-25.1-pyhc872135_2 \n",
      "  python             pkgs/main/win-64::python-3.10.18-h981015d_0 \n",
      "  setuptools         pkgs/main/win-64::setuptools-78.1.1-py310haa95532_0 \n",
      "  sqlite             pkgs/main/win-64::sqlite-3.50.2-hda9a48d_1 \n",
      "  tk                 pkgs/main/win-64::tk-8.6.15-hf199647_0 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "  ucrt               pkgs/main/win-64::ucrt-10.0.22621.0-haa95532_0 \n",
      "  vc                 pkgs/main/win-64::vc-14.3-h2df5915_10 \n",
      "  vc14_runtime       pkgs/main/win-64::vc14_runtime-14.44.35208-h4927774_10 \n",
      "  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.44.35208-ha6b5a95_10 \n",
      "  wheel              pkgs/main/win-64::wheel-0.45.1-py310haa95532_0 \n",
      "  xz                 pkgs/main/win-64::xz-5.6.4-h4754444_1 \n",
      "  zlib               pkgs/main/win-64::zlib-1.2.13-h8cc25b3_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "python-3.10.18       | 16.2 MB   |            |   0% \n",
      "\n",
      "openssl-3.0.17       | 7.8 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "tk-8.6.15            | 3.5 MB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "setuptools-78.1.1    | 1.7 MB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-25.1             | 1.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.50.2        | 1017 KB   |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.6.4             | 280 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.7.1          | 259 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.45.1         | 145 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tzdata-2025b         | 116 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.3              | 19 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-25.1             | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.17       | 7.8 MB    | #4         |  15% \u001b[A\n",
      "python-3.10.18       | 16.2 MB   | 3          |   4% \n",
      "\n",
      "\n",
      "\n",
      "setuptools-78.1.1    | 1.7 MB    | ###2       |  32% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tk-8.6.15            | 3.5 MB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "setuptools-78.1.1    | 1.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.50.2        | 1017 KB   | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "python-3.10.18       | 16.2 MB   | #8         |  18% \n",
      "\n",
      "\n",
      "tk-8.6.15            | 3.5 MB    | ####1      |  41% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tk-8.6.15            | 3.5 MB    | ########5  |  86% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.50.2        | 1017 KB   | #######5   |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.17       | 7.8 MB    | #####1     |  52% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.50.2        | 1017 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | 7          |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | 2          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.50.2        | 1017 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.50.2        | 1017 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tk-8.6.15            | 3.5 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "python-3.10.18       | 16.2 MB   | ##8        |  28% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.6.4             | 280 KB    | 5          |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.6.4             | 280 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.17       | 7.8 MB    | #######5   |  76% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | #5         |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | ########7  |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.7.1          | 259 KB    | 6          |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | #######4   |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.17       | 7.8 MB    | #########7 |  97% \u001b[A\n",
      "python-3.10.18       | 16.2 MB   | ###5       |  35% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.7.1          | 259 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.45.1         | 145 KB    | #1         |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.17       | 7.8 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.45.1         | 145 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | #2         |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tzdata-2025b         | 116 KB    | #3         |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tzdata-2025b         | 116 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     | ########3  |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "python-3.10.18       | 16.2 MB   | ######5    |  65% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.3              | 19 KB     | ########3  |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.3              | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "python-3.10.18       | 16.2 MB   | ########9  |  89% \n",
      "python-3.10.18       | 16.2 MB   | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-25.1             | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-25.1             | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.6.4             | 280 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.6.4             | 280 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.7.1          | 259 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.7.1          | 259 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "setuptools-78.1.1    | 1.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "setuptools-78.1.1    | 1.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.45.1         | 145 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.45.1         | 145 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.17       | 7.8 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.3              | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.3              | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tk-8.6.15            | 3.5 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tzdata-2025b         | 116 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tzdata-2025b         | 116 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "python-3.10.18       | 16.2 MB   | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate form_auto\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create -n form_auto python=3.10 -y\n",
    "!conda activate form_auto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 55.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 47.4 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "Collecting easyocr==1.7.2\n",
      "  Using cached easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting spacy==3.8.7\n",
      "  Downloading spacy-3.8.7-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.2-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting torch (from easyocr==1.7.2)\n",
      "  Downloading torch-2.8.0-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision>=0.5 (from easyocr==1.7.2)\n",
      "  Downloading torchvision-0.23.0-cp310-cp310-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting opencv-python-headless (from easyocr==1.7.2)\n",
      "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from easyocr==1.7.2) (1.26.4)\n",
      "Collecting Pillow (from easyocr==1.7.2)\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting python-bidi (from easyocr==1.7.2)\n",
      "  Downloading python_bidi-0.6.6-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting PyYAML (from easyocr==1.7.2)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Shapely (from easyocr==1.7.2)\n",
      "  Downloading shapely-2.1.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from easyocr==1.7.2)\n",
      "  Downloading pyclipper-1.3.0.post6-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting ninja (from easyocr==1.7.2)\n",
      "  Using cached ninja-1.13.0-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy==3.8.7)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy==3.8.7)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy==3.8.7)\n",
      "  Downloading murmurhash-1.0.13-cp310-cp310-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy==3.8.7)\n",
      "  Downloading cymem-2.0.11-cp310-cp310-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy==3.8.7)\n",
      "  Downloading preshed-3.0.10-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy==3.8.7)\n",
      "  Downloading thinc-8.3.6-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy==3.8.7)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy==3.8.7)\n",
      "  Downloading srsly-2.5.1-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy==3.8.7)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy==3.8.7)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy==3.8.7)\n",
      "  Downloading typer-0.16.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy==3.8.7)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy==3.8.7)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy==3.8.7)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting jinja2 (from spacy==3.8.7)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from spacy==3.8.7) (78.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from spacy==3.8.7) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy==3.8.7)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy==3.8.7)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.7)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.7)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.7) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.7)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy==3.8.7)\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy==3.8.7)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy==3.8.7)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy==3.8.7)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy==3.8.7)\n",
      "  Downloading blis-1.3.0-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy==3.8.7)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy (from easyocr==1.7.2)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy==3.8.7) (0.4.6)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy==3.8.7)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy==3.8.7)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy==3.8.7)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy==3.8.7)\n",
      "  Using cached cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy==3.8.7)\n",
      "  Using cached smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy==3.8.7)\n",
      "  Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting networkx>=3.0 (from scikit-image)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.8.7)\n",
      "  Downloading marisa_trie-1.3.0-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.7)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\t077\\anaconda3\\envs\\form_auto\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.7) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.7)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting filelock (from torch->easyocr==1.7.2)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting sympy>=1.13.3 (from torch->easyocr==1.7.2)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec (from torch->easyocr==1.7.2)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->easyocr==1.7.2)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy==3.8.7)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "Downloading spacy-3.8.7-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 10.5/14.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 44.7 MB/s eta 0:00:00\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp310-cp310-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp310-cp310-win_amd64.whl (117 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 36.0 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp310-cp310-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 632.3/632.3 kB 23.1 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.6-cp310-cp310-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 48.8 MB/s eta 0:00:00\n",
      "Downloading blis-1.3.0-cp310-cp310-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 54.9 MB/s eta 0:00:00\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 34.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 28.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 27.0 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.16.1-py3-none-any.whl (46 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Using cached smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.4/41.3 MB 16.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.9/41.3 MB 36.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 19.4/41.3 MB 31.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 26.2/41.3 MB 31.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 30.9/41.3 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.2/41.3 MB 29.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 30.1 MB/s eta 0:00:00\n",
      "Downloading scikit_image-0.25.2-cp310-cp310-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 6.6/12.8 MB 30.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.8 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 21.1 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading marisa_trie-1.3.0-cp310-cp310-win_amd64.whl (143 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 39.1 MB/s eta 0:00:00\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
      "Downloading torchvision-0.23.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 41.8 MB/s eta 0:00:00\n",
      "Downloading torch-2.8.0-cp310-cp310-win_amd64.whl (241.4 MB)\n",
      "   ---------------------------------------- 0.0/241.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.2/241.4 MB 19.4 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 6.6/241.4 MB 15.5 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 11.3/241.4 MB 18.0 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 18.1/241.4 MB 21.5 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 23.1/241.4 MB 22.1 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 29.6/241.4 MB 23.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 34.3/241.4 MB 23.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 40.4/241.4 MB 24.4 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 46.1/241.4 MB 24.9 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 50.3/241.4 MB 24.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 55.6/241.4 MB 24.6 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 60.8/241.4 MB 24.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 65.5/241.4 MB 24.4 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 70.0/241.4 MB 24.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 75.0/241.4 MB 24.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 79.4/241.4 MB 24.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 83.9/241.4 MB 24.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 88.9/241.4 MB 24.0 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 93.6/241.4 MB 24.1 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 98.6/241.4 MB 24.1 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 102.5/241.4 MB 23.8 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 108.8/241.4 MB 24.2 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 113.2/241.4 MB 24.1 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 116.9/241.4 MB 23.9 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 122.4/241.4 MB 24.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 126.4/241.4 MB 23.7 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 132.9/241.4 MB 24.0 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 138.7/241.4 MB 24.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 143.4/241.4 MB 24.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 149.9/241.4 MB 24.4 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 155.2/241.4 MB 24.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 160.7/241.4 MB 24.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 165.9/241.4 MB 24.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 171.7/241.4 MB 24.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 176.9/241.4 MB 24.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 182.7/241.4 MB 24.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 186.9/241.4 MB 24.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 194.0/241.4 MB 25.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 199.8/241.4 MB 25.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 205.3/241.4 MB 25.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 211.3/241.4 MB 25.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 215.7/241.4 MB 25.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 221.2/241.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 227.3/241.4 MB 25.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 232.5/241.4 MB 25.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  239.1/241.4 MB 25.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.4 MB 25.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.4/241.4 MB 24.8 MB/s eta 0:00:00\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached ninja-1.13.0-py3-none-win_amd64.whl (309 kB)\n",
      "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n",
      "Downloading pyclipper-1.3.0.post6-cp310-cp310-win_amd64.whl (110 kB)\n",
      "Downloading python_bidi-0.6.6-cp310-cp310-win_amd64.whl (160 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading shapely-2.1.1-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 30.7 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, mpmath, cymem, wrapt, wasabi, urllib3, typing-inspection, tqdm, sympy, spacy-loggers, spacy-legacy, shellingham, PyYAML, pydantic-core, Pillow, numpy, ninja, networkx, murmurhash, mdurl, MarkupSafe, marisa-trie, lazy-loader, idna, fsspec, filelock, cloudpathlib, click, charset_normalizer, certifi, catalogue, annotated-types, tifffile, srsly, smart-open, Shapely, scipy, requests, pydantic, preshed, opencv-python-headless, opencv-python, markdown-it-py, language-data, jinja2, imageio, blis, torch, scikit-image, rich, langcodes, confection, typer, torchvision, thinc, weasel, easyocr, spacy\n",
      "\n",
      "   - --------------------------------------  2/59 [mpmath]\n",
      "   - --------------------------------------  2/59 [mpmath]\n",
      "   - --------------------------------------  2/59 [mpmath]\n",
      "   - --------------------------------------  2/59 [mpmath]\n",
      "   --- ------------------------------------  5/59 [wasabi]\n",
      "   ---- -----------------------------------  6/59 [urllib3]\n",
      "   ----- ----------------------------------  8/59 [tqdm]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ ---------------------------------  9/59 [sympy]\n",
      "   ------ --------------------------------- 10/59 [spacy-loggers]\n",
      "   -------- ------------------------------- 13/59 [PyYAML]\n",
      "   ---------- ----------------------------- 15/59 [Pillow]\n",
      "   ---------- ----------------------------- 15/59 [Pillow]\n",
      "   ---------- ----------------------------- 15/59 [Pillow]\n",
      "   ---------- ----------------------------- 15/59 [Pillow]\n",
      "  Attempting uninstall: numpy\n",
      "   ---------- ----------------------------- 15/59 [Pillow]\n",
      "    Found existing installation: numpy 1.26.4\n",
      "   ---------- ----------------------------- 15/59 [Pillow]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ---------- ----------------------------- 16/59 [numpy]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 18/59 [networkx]\n",
      "   ------------ --------------------------- 19/59 [murmurhash]\n",
      "   ---------------- ----------------------- 24/59 [idna]\n",
      "   ---------------- ----------------------- 25/59 [fsspec]\n",
      "   ---------------- ----------------------- 25/59 [fsspec]\n",
      "   ------------------ --------------------- 27/59 [cloudpathlib]\n",
      "   ------------------- -------------------- 29/59 [charset_normalizer]\n",
      "   ---------------------- ----------------- 33/59 [tifffile]\n",
      "   ---------------------- ----------------- 33/59 [tifffile]\n",
      "   ----------------------- ---------------- 34/59 [srsly]\n",
      "   ----------------------- ---------------- 34/59 [srsly]\n",
      "   ----------------------- ---------------- 34/59 [srsly]\n",
      "   ------------------------ --------------- 36/59 [Shapely]\n",
      "   ------------------------ --------------- 36/59 [Shapely]\n",
      "   ------------------------ --------------- 36/59 [Shapely]\n",
      "   ------------------------ --------------- 36/59 [Shapely]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   ------------------------- -------------- 37/59 [scipy]\n",
      "   -------------------------- ------------- 39/59 [pydantic]\n",
      "   -------------------------- ------------- 39/59 [pydantic]\n",
      "   -------------------------- ------------- 39/59 [pydantic]\n",
      "   -------------------------- ------------- 39/59 [pydantic]\n",
      "   --------------------------- ------------ 41/59 [opencv-python-headless]\n",
      "   --------------------------- ------------ 41/59 [opencv-python-headless]\n",
      "   --------------------------- ------------ 41/59 [opencv-python-headless]\n",
      "   --------------------------- ------------ 41/59 [opencv-python-headless]\n",
      "   ---------------------------- ----------- 42/59 [opencv-python]\n",
      "   ---------------------------- ----------- 42/59 [opencv-python]\n",
      "   ---------------------------- ----------- 42/59 [opencv-python]\n",
      "   ---------------------------- ----------- 42/59 [opencv-python]\n",
      "   ----------------------------- ---------- 43/59 [markdown-it-py]\n",
      "   ----------------------------- ---------- 43/59 [markdown-it-py]\n",
      "   ----------------------------- ---------- 44/59 [language-data]\n",
      "   ----------------------------- ---------- 44/59 [language-data]\n",
      "   ----------------------------- ---------- 44/59 [language-data]\n",
      "   ----------------------------- ---------- 44/59 [language-data]\n",
      "   ----------------------------- ---------- 44/59 [language-data]\n",
      "   ----------------------------- ---------- 44/59 [language-data]\n",
      "   ----------------------------- ---------- 44/59 [language-data]\n",
      "   ------------------------------ --------- 45/59 [jinja2]\n",
      "   ------------------------------- -------- 46/59 [imageio]\n",
      "   ------------------------------- -------- 46/59 [imageio]\n",
      "   ------------------------------- -------- 47/59 [blis]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   -------------------------------- ------- 48/59 [torch]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 49/59 [scikit-image]\n",
      "   --------------------------------- ------ 50/59 [rich]\n",
      "   --------------------------------- ------ 50/59 [rich]\n",
      "   --------------------------------- ------ 50/59 [rich]\n",
      "   ----------------------------------- ---- 53/59 [typer]\n",
      "   ------------------------------------ --- 54/59 [torchvision]\n",
      "   ------------------------------------ --- 54/59 [torchvision]\n",
      "   ------------------------------------ --- 54/59 [torchvision]\n",
      "   ------------------------------------ --- 54/59 [torchvision]\n",
      "   ------------------------------------ --- 54/59 [torchvision]\n",
      "   ------------------------------------ --- 54/59 [torchvision]\n",
      "   ------------------------------------- -- 55/59 [thinc]\n",
      "   ------------------------------------- -- 55/59 [thinc]\n",
      "   ------------------------------------- -- 55/59 [thinc]\n",
      "   ------------------------------------- -- 55/59 [thinc]\n",
      "   ------------------------------------- -- 55/59 [thinc]\n",
      "   ------------------------------------- -- 56/59 [weasel]\n",
      "   -------------------------------------- - 57/59 [easyocr]\n",
      "   -------------------------------------- - 57/59 [easyocr]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------  58/59 [spacy]\n",
      "   ---------------------------------------- 59/59 [spacy]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.3.0 PyYAML-6.0.2 Shapely-2.1.1 annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 certifi-2025.8.3 charset_normalizer-3.4.3 click-8.2.1 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 easyocr-1.7.2 filelock-3.19.1 fsspec-2025.7.0 idna-3.10 imageio-2.37.0 jinja2-3.1.6 langcodes-3.5.0 language-data-1.3.0 lazy-loader-0.4 marisa-trie-1.3.0 markdown-it-py-4.0.0 mdurl-0.1.2 mpmath-1.3.0 murmurhash-1.0.13 networkx-3.4.2 ninja-1.13.0 numpy-2.2.6 opencv-python-4.12.0.88 opencv-python-headless-4.12.0.88 preshed-3.0.10 pyclipper-1.3.0.post6 pydantic-2.11.7 pydantic-core-2.33.2 python-bidi-0.6.6 requests-2.32.5 rich-14.1.0 scikit-image-0.25.2 scipy-1.15.3 shellingham-1.5.4 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 sympy-1.14.0 thinc-8.3.6 tifffile-2025.5.10 torch-2.8.0 torchvision-0.23.0 tqdm-4.67.1 typer-0.16.1 typing-inspection-0.4.1 urllib3-2.5.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.3\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------  12.6/12.8 MB 56.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 53.6 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4\n",
    "!pip install easyocr==1.7.2 spacy==3.8.7 opencv-python scipy scikit-image\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.15.2\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scipy==1.15.2) (1.26.4)\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 12.1/40.9 MB 58.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 21.2/40.9 MB 53.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 26.2/40.9 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.2/40.9 MB 39.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.8/40.9 MB 39.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 37.2 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "Successfully installed scipy-1.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\n",
      "'ip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless==4.7.0.72\n",
      "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from opencv-python-headless==4.7.0.72) (1.26.4)\n",
      "Downloading opencv_python_headless-4.7.0.72-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 12.3/38.1 MB 59.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 19.9/38.1 MB 48.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.7/38.1 MB 41.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 30.9/38.1 MB 37.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.2/38.1 MB 35.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 32.7 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python-headless\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.12.0.88\n",
      "    Uninstalling opencv-python-headless-4.12.0.88:\n",
      "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
      "Successfully installed opencv-python-headless-4.7.0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\T077\\anaconda3\\Lib\\site-packages\\~v2'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr==1.7.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (0.23.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (4.7.0.72)\n",
      "Requirement already satisfied: scipy in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (1.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (10.4.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (0.6.6)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (6.0.1)\n",
      "Requirement already satisfied: Shapely in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (2.1.1)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\t077\\anaconda3\\lib\\site-packages (from easyocr==1.7.2) (1.13.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr==1.7.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr==1.7.2) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr==1.7.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr==1.7.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr==1.7.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr==1.7.2) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\t077\\anaconda3\\lib\\site-packages (from torch->easyocr==1.7.2) (75.1.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr==1.7.2) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr==1.7.2) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr==1.7.2) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from scikit-image->easyocr==1.7.2) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->easyocr==1.7.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from jinja2->torch->easyocr==1.7.2) (2.1.3)\n",
      "Requirement already satisfied: spacy==3.8.7 in c:\\users\\t077\\anaconda3\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from spacy==3.8.7) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.8.7) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.7) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.7) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.7) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.7) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.7) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.7) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.7) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy==3.8.7) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy==3.8.7) (0.1.5)\n",
      "Collecting numpy>=1.19.0 (from spacy==3.8.7)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\t077\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy==3.8.7) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy==3.8.7) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.7) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.7) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from jinja2->spacy==3.8.7) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\t077\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.8.7) (1.3.0)\n",
      "Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------  12.6/12.8 MB 56.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 53.5 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.2 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\thinc\\compat.py\", line 99, in <module>\n",
      "    import h5py\n",
      "  File \"c:\\Users\\T077\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py\", line 45, in <module>\n",
      "    from ._conv import register_converters as _register_converters, \\\n",
      "  File \"h5py\\\\_conv.pyx\", line 1, in init h5py._conv\n",
      "  File \"h5py\\\\h5r.pyx\", line 1, in init h5py.h5r\n",
      "  File \"h5py\\\\h5p.pyx\", line 1, in init h5py.h5p\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4\n",
    "!pip install scipy==1.15.2\n",
    "!ip install opencv-python==4.7.0.72\n",
    "!pip install opencv-python-headless==4.7.0.72\n",
    "!pip install easyocr==1.7.2\n",
    "!pip install spacy==3.8.7\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
